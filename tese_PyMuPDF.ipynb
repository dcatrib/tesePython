{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dcatrib/tesePython/blob/main/tese_PyMuPDF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KLlzG5xH9C2Q",
        "outputId": "074c096b-a78f-47c0-f085-1f2fdf322420"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyMuPDF\n",
            "  Downloading PyMuPDF-1.24.11-cp38-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Collecting selenium\n",
            "  Downloading selenium-4.25.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting chromedriver-autoinstaller\n",
            "  Downloading chromedriver_autoinstaller-0.6.4-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Collecting trio~=0.17 (from selenium)\n",
            "  Downloading trio-0.26.2-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting trio-websocket~=0.9 (from selenium)\n",
            "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.10/dist-packages (from selenium) (4.12.2)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.10/dist-packages (from chromedriver-autoinstaller) (24.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (24.2.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Collecting outcome (from trio~=0.17->selenium)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.2.2)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Downloading PyMuPDF-1.24.11-cp38-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (19.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.6/19.6 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading selenium-4.25.0-py3-none-any.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chromedriver_autoinstaller-0.6.4-py3-none-any.whl (7.6 kB)\n",
            "Downloading trio-0.26.2-py3-none-any.whl (475 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m476.0/476.0 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
            "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDF, outcome, h11, chromedriver-autoinstaller, wsproto, trio, trio-websocket, selenium\n",
            "Successfully installed PyMuPDF-1.24.11 chromedriver-autoinstaller-0.6.4 h11-0.14.0 outcome-1.3.0.post0 selenium-4.25.0 trio-0.26.2 trio-websocket-0.11.1 wsproto-1.2.0\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Ign:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy Release [5,713 B]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy Release.gpg [793 B]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,031 kB]\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:11 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,593 kB]\n",
            "Hit:13 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,319 kB]\n",
            "Hit:15 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,447 kB]\n",
            "Get:17 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,378 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,159 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,200 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,600 kB]\n",
            "Get:21 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [27.8 kB]\n",
            "Fetched 23.0 MB in 5s (4,784 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "wget is already the newest version (1.21.2-2ubuntu1.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "--2024-10-09 12:43:13--  https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
            "Resolving dl.google.com (dl.google.com)... 172.253.117.93, 172.253.117.190, 172.253.117.136, ...\n",
            "Connecting to dl.google.com (dl.google.com)|172.253.117.93|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 110925276 (106M) [application/x-debian-package]\n",
            "Saving to: ‘google-chrome-stable_current_amd64.deb’\n",
            "\n",
            "google-chrome-stabl 100%[===================>] 105.79M   210MB/s    in 0.5s    \n",
            "\n",
            "2024-10-09 12:43:14 (210 MB/s) - ‘google-chrome-stable_current_amd64.deb’ saved [110925276/110925276]\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Note, selecting 'google-chrome-stable' instead of './google-chrome-stable_current_amd64.deb'\n",
            "The following additional packages will be installed:\n",
            "  libvulkan1 mesa-vulkan-drivers\n",
            "The following NEW packages will be installed:\n",
            "  google-chrome-stable libvulkan1 mesa-vulkan-drivers\n",
            "0 upgraded, 3 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 10.9 MB/122 MB of archives.\n",
            "After this operation, 413 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libvulkan1 amd64 1.3.204.1-2 [128 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 mesa-vulkan-drivers amd64 23.2.1-1ubuntu3.1~22.04.2 [10.7 MB]\n",
            "Get:3 /content/google-chrome-stable_current_amd64.deb google-chrome-stable amd64 129.0.6668.100-1 [111 MB]\n",
            "Fetched 10.9 MB in 2s (5,377 kB/s)\n",
            "Selecting previously unselected package libvulkan1:amd64.\n",
            "(Reading database ... 123621 files and directories currently installed.)\n",
            "Preparing to unpack .../libvulkan1_1.3.204.1-2_amd64.deb ...\n",
            "Unpacking libvulkan1:amd64 (1.3.204.1-2) ...\n",
            "Selecting previously unselected package google-chrome-stable.\n",
            "Preparing to unpack .../google-chrome-stable_current_amd64.deb ...\n",
            "Unpacking google-chrome-stable (129.0.6668.100-1) ...\n",
            "Selecting previously unselected package mesa-vulkan-drivers:amd64.\n",
            "Preparing to unpack .../mesa-vulkan-drivers_23.2.1-1ubuntu3.1~22.04.2_amd64.deb ...\n",
            "Unpacking mesa-vulkan-drivers:amd64 (23.2.1-1ubuntu3.1~22.04.2) ...\n",
            "Setting up libvulkan1:amd64 (1.3.204.1-2) ...\n",
            "Setting up mesa-vulkan-drivers:amd64 (23.2.1-1ubuntu3.1~22.04.2) ...\n",
            "Setting up google-chrome-stable (129.0.6668.100-1) ...\n",
            "update-alternatives: using /usr/bin/google-chrome-stable to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/google-chrome-stable to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/google-chrome-stable to provide /usr/bin/google-chrome (google-chrome) in auto mode\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install PyMuPDF requests selenium chromedriver-autoinstaller pandas nltk gensim numpy\n",
        "\n",
        "!apt-get update\n",
        "!apt-get install -y wget\n",
        "!wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
        "!apt-get install -y ./google-chrome-stable_current_amd64.deb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "collapsed": true,
        "id": "AyVkOEFexu7A"
      },
      "outputs": [],
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.common.exceptions import NoSuchElementException, TimeoutException, StaleElementReferenceException\n",
        "import chromedriver_autoinstaller\n",
        "import requests\n",
        "import fitz\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "from gensim.models import KeyedVectors, Word2Vec\n",
        "import gensim\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from statsmodels.tsa.ar_model import AutoReg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "collapsed": true,
        "id": "MqPHOhrtxvNR",
        "outputId": "bd81b246-dee3-470e-d68e-1755f540acdb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/usr/local/lib/python3.10/dist-packages/chromedriver_autoinstaller/129/chromedriver'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Configurando o WebDriver\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "\n",
        "# Instala automaticamente a versão correta do ChromeDriver\n",
        "chromedriver_autoinstaller.install()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "N6MM2g-p7BdE"
      },
      "outputs": [],
      "source": [
        "# URL para scrape\n",
        "url = \"https://www.bcb.gov.br/en/publications/copomminutes/cronologicos\"\n",
        "\n",
        "# Criar uma nova instância do Chrome driver\n",
        "driver = webdriver.Chrome(options=chrome_options)\n",
        "driver.get(url)\n",
        "\n",
        "# Esperar o seletor específico estar presente\n",
        "WebDriverWait(driver, 15).until(\n",
        "    EC.presence_of_element_located((By.CSS_SELECTOR, 'body > app-root > app-root > main > dynamic-comp > div > div > bcb-publicacao > div > div > bcb-ultimaspublicacoes > div'))\n",
        ")\n",
        "\n",
        "# Definir o seletor\n",
        "selector = 'body > app-root > app-root > main > dynamic-comp > div > div > bcb-publicacao > div > div > bcb-ultimaspublicacoes > div'\n",
        "\n",
        "# Lista para armazenar hrefs, textos e links de download\n",
        "hrefs_and_texts = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "uXBHUR-O7HRi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2315feae-924b-485a-e2ee-c5840b9b5b72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n"
          ]
        }
      ],
      "source": [
        "# Função para recuperar links e botões de download\n",
        "def retrieve_links():\n",
        "    try:\n",
        "        elements = driver.find_elements(By.CSS_SELECTOR, selector)\n",
        "        link_count = 0  # Inicializa um contador para os links\n",
        "        for element in elements:\n",
        "            links = element.find_elements(By.TAG_NAME, 'a')\n",
        "            for link in links:\n",
        "                if link_count >= 200:  # Limita a 50 links\n",
        "                    return  # Sai da função se 50 links foram processados\n",
        "                href = link.get_attribute('href')\n",
        "                text = link.text\n",
        "                if href and text and text[0].isdigit():\n",
        "                    driver.get(href)\n",
        "                    # Esperar o botão de download\n",
        "                    try:\n",
        "                        download_button = WebDriverWait(driver, 45).until(\n",
        "                            EC.presence_of_element_located((By.CSS_SELECTOR, '#publicacao > div.col-lg-9.d-flex.flex-column > div > div > div > div.d-flex.flex-column-reverse.flex-sm-row.justify-content-sm-between.align-items-sm-center > div.d-flex.align-items-center.mb-3.mb-sm-0.d-print-none > download > div > div > a'))\n",
        "                        )\n",
        "                        download_href = download_button.get_attribute('href')\n",
        "\n",
        "                        # Fazer download do PDF\n",
        "                        pdf_response = requests.get(download_href)\n",
        "                        pdf_filename = f\"{text}.pdf\"\n",
        "                        with open(pdf_filename, 'wb') as pdf_file:\n",
        "                            pdf_file.write(pdf_response.content)\n",
        "\n",
        "                        # Extrair texto do PDF usando PyMuPDF\n",
        "                        pdf_text = ''\n",
        "                        with fitz.open(pdf_filename) as pdf_file:\n",
        "                            for page in pdf_file:\n",
        "                                page_text = page.get_text()\n",
        "                                pdf_text += page_text + '\\n'\n",
        "\n",
        "                        # Limpeza do texto\n",
        "                        pdf_text = pdf_text.replace('\\n', ' ')  # Remove quebras de linha\n",
        "                        pdf_text = re.sub(r'\\s+', ' ', pdf_text)  # Substitui múltiplos espaços por um único\n",
        "                        pdf_text = pdf_text.strip()  # Remove espaços no início e no fim\n",
        "\n",
        "                        # Print da primeira linha extraída\n",
        "                        first_line = pdf_text.split('.')[0]  # Considera a primeira frase\n",
        "                        #print(f'Primeira linha extraída: {first_line.strip()}')\n",
        "                        print(link_count)\n",
        "                    except (NoSuchElementException, TimeoutException):\n",
        "                        download_href = None\n",
        "                        pdf_text = None\n",
        "\n",
        "                    hrefs_and_texts.append((href, text, download_href, pdf_text))\n",
        "                    link_count += 1  # Incrementa o contador\n",
        "                    driver.back()\n",
        "                    WebDriverWait(driver, 15).until(EC.presence_of_element_located((By.CSS_SELECTOR, selector)))\n",
        "    except StaleElementReferenceException:\n",
        "        retrieve_links()\n",
        "\n",
        "# Iniciar a recuperação de links\n",
        "retrieve_links()\n",
        "\n",
        "# Fechar o driver\n",
        "driver.quit()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvLYZn946Hlr"
      },
      "source": [
        "Minhas stopwords e expressoes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "D7_zXjpX6HUz"
      },
      "outputs": [],
      "source": [
        "# Minhas stopwords\n",
        "my_stopwords = {\n",
        "    'January', 'February', 'March', 'April', 'May', 'June', 'July',\n",
        "    'August', 'September', 'October', 'November', 'December','january', 'february', 'march', 'april', 'may', 'june', 'July',\n",
        "    'august', 'september', 'october', 'november', 'december',\n",
        "    'minutes', 'bcb', 'th', 'copom', 'bcbgovbr', 'brasilia', 'pm','roberto'\n",
        "}\n",
        "\n",
        "# Array de expressões a serem removidas\n",
        "expressions_to_remove = [\n",
        "    'bcb.gov.br Minutes of the Meeting of the Monetary Policy Committee — Copom',\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Is8XaMx7-BIN"
      },
      "source": [
        "fazer o preprocessamento e criar o df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jRdPCx--8pb-",
        "outputId": "f80c2547-fcb9-4578-cff7-e5c5627990c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  Link  \\\n",
            "0    https://www.bcb.gov.br/en/publications/copommi...   \n",
            "1    https://www.bcb.gov.br/en/publications/copommi...   \n",
            "2    https://www.bcb.gov.br/en/publications/copommi...   \n",
            "3    https://www.bcb.gov.br/en/publications/copommi...   \n",
            "4    https://www.bcb.gov.br/en/publications/copommi...   \n",
            "..                                                 ...   \n",
            "195  https://www.bcb.gov.br/en/publications/copommi...   \n",
            "196  https://www.bcb.gov.br/en/publications/copommi...   \n",
            "197  https://www.bcb.gov.br/en/publications/copommi...   \n",
            "198  https://www.bcb.gov.br/en/publications/copommi...   \n",
            "199  https://www.bcb.gov.br/en/publications/copommi...   \n",
            "\n",
            "                                     Texto  \\\n",
            "0    265th Meeting - September 17-18, 2024   \n",
            "1         264th Meeting - July 30-31, 2024   \n",
            "2         263rd Meeting - June 18-19, 2024   \n",
            "3            262nd Meeting - May 7-8, 2024   \n",
            "4        261st Meeting - March 19-20, 2024   \n",
            "..                                     ...   \n",
            "195        70th Copom minutes - April 2002   \n",
            "196        69th Copom minutes - April 2002   \n",
            "197        68th Copom minutes - March 2002   \n",
            "198     67th Copom minutes - February 2002   \n",
            "199      66th Copom minutes - January 2002   \n",
            "\n",
            "                                      Link de Download  \\\n",
            "0    https://www.bcb.gov.br/content/copom/copomminu...   \n",
            "1    https://www.bcb.gov.br/content/copom/copomminu...   \n",
            "2    https://www.bcb.gov.br/content/copom/copomminu...   \n",
            "3    https://www.bcb.gov.br/content/copom/copomminu...   \n",
            "4    https://www.bcb.gov.br/content/copom/copomminu...   \n",
            "..                                                 ...   \n",
            "195  https://www.bcb.gov.br/content/copom/copomminu...   \n",
            "196  https://www.bcb.gov.br/content/copom/copomminu...   \n",
            "197  https://www.bcb.gov.br/content/copom/copomminu...   \n",
            "198  https://www.bcb.gov.br/content/copom/copomminu...   \n",
            "199  https://www.bcb.gov.br/content/copom/copomminu...   \n",
            "\n",
            "                                          Texto do PDF  \\\n",
            "0    1 bcb.gov.br Minutes of the Meeting of the Mon...   \n",
            "1    1 bcb.gov.br Minutes of the Meeting of the Mon...   \n",
            "2    1 bcb.gov.br Minutes of the Meeting of the Mon...   \n",
            "3    1 bcb.gov.br Minutes of the Meeting of the Mon...   \n",
            "4    1 bcb.gov.br Minutes of the Meeting of the Mon...   \n",
            "..                                                 ...   \n",
            "195  April 29th, 2002 MINUTES OF THE 70th MEETING O...   \n",
            "196  Information for unrestricted disclosure. It is...   \n",
            "197  March 4th, 2002 MINUTES OF THE 68th MEETING OF...   \n",
            "198  February 4th, 2002 MINUTES OF THE 67th MEETING...   \n",
            "199  January 3rd, 2002 MINUTES OF THE 66th MEETING ...   \n",
            "\n",
            "                                      Texto Processado  \n",
            "0    meeting monetary policy committee meeting date...  \n",
            "1    meeting monetary policy committee july meeting...  \n",
            "2    meeting monetary policy committee rd rd meetin...  \n",
            "3    meeting monetary policy committee nd nd meetin...  \n",
            "4    meeting monetary policy committee st st meetin...  \n",
            "..                                                 ...  \n",
            "195  meeting banco central brasil monetary policy c...  \n",
            "196  information unrestricted disclosure intended b...  \n",
            "197  meeting banco central brasil monetary policy c...  \n",
            "198  meeting banco central brasil monetary policy c...  \n",
            "199  rd meeting banco central brasil monetary polic...  \n",
            "\n",
            "[200 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "# Baixar as stopwords se ainda não tiver feito\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Criar um DataFrame com os links e textos extraídos\n",
        "df = pd.DataFrame(hrefs_and_texts, columns=['Link', 'Texto', 'Link de Download', 'Texto do PDF'])\n",
        "\n",
        "# Carregar stopwords em inglês\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stop_words.update(my_stopwords)\n",
        "\n",
        "# Função para preprocessar o texto\n",
        "def preprocess_text(text):\n",
        "    if text:\n",
        "        # Remover números, pontuação e caracteres especiais\n",
        "        text = re.sub(r'[0-9]+', '', text)  # Remove números\n",
        "        # Remover pontuação, exceto parênteses\n",
        "        text = re.sub(r'[^\\w\\s()]+', '', text)  # Mantém letras, números, espaços e parênteses\n",
        "        text = re.sub(r'\\s+', ' ', text)  # Substituir múltiplos espaços por um único espaço\n",
        "        text = text.strip().lower()  # Retorna texto em minúsculas\n",
        "\n",
        "        # Remover expressões específicas\n",
        "        for expr in expressions_to_remove:\n",
        "            text = text.replace(expr, '')\n",
        "\n",
        "        # Remover stopwords\n",
        "        text = ' '.join([word for word in text.split() if word not in stop_words])\n",
        "        return text\n",
        "    return ''\n",
        "\n",
        "# Criar a nova coluna 'Texto Processado'\n",
        "df['Texto Processado'] = df['Texto do PDF'].apply(preprocess_text)\n",
        "\n",
        "# Imprimir o DataFrame\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "collapsed": true,
        "id": "pd-A0QrjI-xe"
      },
      "outputs": [],
      "source": [
        "# Função para extrair ano e mês\n",
        "def extract_year_month(text):\n",
        "    # Caso 1: Formato com dia e mês\n",
        "    match_full = re.search(r'(\\w+)\\s+\\d{1,2}[- ]\\d{1,2},\\s*(\\d{4})', text)\n",
        "    # Caso 2: Formato apenas com mês e ano\n",
        "    match_month_year = re.search(r'(\\w+)\\s+(\\d{4})', text)\n",
        "    # Caso 3: Formato com intervalo de datas\n",
        "    match_interval = re.search(r'(\\w+)\\s+\\d{1,2}\\s*-\\s*(\\w+)\\s+\\d{1,2},\\s*(\\d{4})', text)\n",
        "\n",
        "    if match_full:\n",
        "        month_str = match_full.group(1)\n",
        "        year = match_full.group(2)\n",
        "    elif match_month_year:\n",
        "        month_str = match_month_year.group(1)\n",
        "        year = match_month_year.group(2)\n",
        "    elif match_interval:\n",
        "        month_str = match_interval.group(2)  # Captura o mês da última data\n",
        "        year = match_interval.group(3)\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "    # Converter mês para número\n",
        "    month_num = pd.to_datetime(month_str, format='%B').month\n",
        "    return f\"{year}-{month_num:02d}\"  # Formatar como YYYY-MM\n",
        "\n",
        "# Criar nova coluna com ano e mês\n",
        "df['Ano_Mes'] = df['Texto'].apply(extract_year_month)\n",
        "\n",
        "# Exibir o DataFrame resultante\n",
        "#print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "nFcN5ZtWbdxE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4896b9ba-255d-44dc-a87e-8208799c1a58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                      Texto Processado\n",
            "0    a) update economic outlook copoms scenario glo...\n",
            "1    a) update economic outlook copoms scenario glo...\n",
            "2    a) update economic outlook copoms scenario glo...\n",
            "3    a) update economic outlook copoms scenario glo...\n",
            "4    a) update economic outlook copoms scenario glo...\n",
            "..                                                 ...\n",
            "195  meeting banco central brasil monetary policy c...\n",
            "196  information unrestricted disclosure intended b...\n",
            "197  meeting banco central brasil monetary policy c...\n",
            "198  meeting banco central brasil monetary policy c...\n",
            "199  rd meeting banco central brasil monetary polic...\n",
            "\n",
            "[200 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "# Definir as expressões que você deseja encontrar\n",
        "expressions = [\n",
        "    r'(?i)(A\\)\\s*update (?:e conomic|economic) outlook (?:c opoms|copoms) (?:reference|baseline|)\\s*scenario)(.*)',\n",
        "    r'(?i)(Recent Economic Developments)(.*)',\n",
        "    r'(?i)(Recent Evolution Inflation)(.*)',\n",
        "]\n",
        "\n",
        "# Função para extrair texto a partir de várias expressões\n",
        "def extract_from_expressions(text):\n",
        "    for pattern in expressions:\n",
        "        match = re.search(pattern, text)\n",
        "        if match:\n",
        "            # Retorna o texto a partir da expressão encontrada até o final\n",
        "            return text[match.start():]  # A partir do início da expressão até o final do texto\n",
        "    return text  # Retorna todo o texto se nenhuma expressão for encontrada\n",
        "\n",
        "df['Texto Processado'] = df['Texto Processado'].apply(extract_from_expressions)\n",
        "\n",
        "\n",
        "# Definir os títulos das seções, permitindo variações com ou sem espaço\n",
        "section_titles = [\n",
        "    r'(?i)A\\)\\s*update (?:e conomic|economic) outlook (?:c opoms|copoms) (?:reference|baseline|)\\s*scenario.*?(?=B\\)\\s*risks around|B\\)\\s*scenarios risk analysis|$)',\n",
        "    r'(?i)(B\\)\\s*risks around|B\\)\\s*scenarios risk analysis).*?(?=C\\)\\s*discussion conduct monetary policy|$)',\n",
        "    r'(?i)C\\)\\s*discussion conduct monetary policy.*?(?=D\\)\\s*monetary policy decision|$)',\n",
        "    r'(?i)D\\)\\s*monetary policy decision.*?(?=Footnotes|$)',\n",
        "    r'(?i)Footnotes.*'  # Captura tudo até o final do texto\n",
        "]\n",
        "\n",
        "\n",
        "# Criar variáveis para cada seção no DataFrame\n",
        "for title in section_titles:\n",
        "    # Usar str.extract para capturar as seções\n",
        "    section_name = re.search(r'A|B|C|D|Footnotes', title).group(0)  # Captura A, B, C, D ou Footnotes\n",
        "    df[section_name] = df['Texto Processado'].str.extract(f'({title})')[0]\n",
        "\n",
        "print (df[['Texto Processado']])\n",
        "# Exibir o DataFrame resultante\n",
        "#print(df[['A', 'B', 'C', 'D', 'Footnotes']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezMA27xpdUbv"
      },
      "source": [
        "Carregar a base dos pibs trimestrais"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "jDDlDELndUq1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3b5ea957-6bfd-4806-c1c3-ee66343b04e8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-96129302-d898-4b29-a911-061d801e4e14\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-96129302-d898-4b29-a911-061d801e4e14\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving pib_trimestral.csv to pib_trimestral (1).csv\n",
            "DataFrame após a leitura:\n",
            "   1º trimestre 1996  2º trimestre 1996  3º trimestre 1996  4º trimestre 1996  \\\n",
            "0                2.5                2.1                2.3                2.2   \n",
            "\n",
            "   1º trimestre 1997  2º trimestre 1997  3º trimestre 1997  4º trimestre 1997  \\\n",
            "0                3.2                4.0                3.0                3.4   \n",
            "\n",
            "   1º trimestre 1998  2º trimestre 1998  ...  1º trimestre 2022  \\\n",
            "0                2.8                2.0  ...                4.7   \n",
            "\n",
            "   2º trimestre 2022  3º trimestre 2022  4º trimestre 2022  1º trimestre 2023  \\\n",
            "0                2.7                2.7                3.0                3.7   \n",
            "\n",
            "   2º trimestre 2023  3º trimestre 2023  4º trimestre 2023  1º trimestre 2024  \\\n",
            "0                3.7                3.1                2.9                2.5   \n",
            "\n",
            "   2º trimestre 2024  \n",
            "0                2.5  \n",
            "\n",
            "[1 rows x 114 columns]\n",
            "DataFrame derretido:\n",
            "           Trimestre  Valor\n",
            "0  1º trimestre 1996    2.5\n",
            "1  2º trimestre 1996    2.1\n",
            "2  3º trimestre 1996    2.3\n",
            "3  4º trimestre 1996    2.2\n",
            "4  1º trimestre 1997    3.2\n",
            "DataFrame com o mapeamento:\n",
            "            Trimestre  Ano_Mes\n",
            "0   1º trimestre 1996  1996-03\n",
            "1   2º trimestre 1996  1996-06\n",
            "2   3º trimestre 1996  1996-09\n",
            "3   4º trimestre 1996  1996-12\n",
            "4   1º trimestre 1997  1997-03\n",
            "5   2º trimestre 1997  1997-06\n",
            "6   3º trimestre 1997  1997-09\n",
            "7   4º trimestre 1997  1997-12\n",
            "8   1º trimestre 1998  1998-03\n",
            "9   2º trimestre 1998  1998-06\n",
            "10  3º trimestre 1998  1998-09\n",
            "11  4º trimestre 1998  1998-12\n",
            "12  1º trimestre 1999  1999-03\n",
            "13  2º trimestre 1999  1999-06\n",
            "14  3º trimestre 1999  1999-09\n",
            "15  4º trimestre 1999  1999-12\n",
            "16  1º trimestre 2000  2000-03\n",
            "17  2º trimestre 2000  2000-06\n",
            "18  3º trimestre 2000  2000-09\n",
            "19  4º trimestre 2000  2000-12\n",
            "Número de valores ausentes em 'Ano_Mes': 0\n",
            "1º trimestre 1996: ['1996-03']\n",
            "2º trimestre 1996: ['1996-06']\n",
            "3º trimestre 1996: ['1996-09']\n",
            "4º trimestre 1996: ['1996-12']\n",
            "1º trimestre 1997: ['1997-03']\n",
            "2º trimestre 1997: ['1997-06']\n",
            "3º trimestre 1997: ['1997-09']\n",
            "4º trimestre 1997: ['1997-12']\n",
            "1º trimestre 1998: ['1998-03']\n",
            "2º trimestre 1998: ['1998-06']\n",
            "3º trimestre 1998: ['1998-09']\n",
            "4º trimestre 1998: ['1998-12']\n",
            "1º trimestre 1999: ['1999-03']\n",
            "2º trimestre 1999: ['1999-06']\n",
            "3º trimestre 1999: ['1999-09']\n",
            "4º trimestre 1999: ['1999-12']\n",
            "1º trimestre 2000: ['2000-03']\n",
            "2º trimestre 2000: ['2000-06']\n",
            "3º trimestre 2000: ['2000-09']\n",
            "4º trimestre 2000: ['2000-12']\n",
            "1º trimestre 2001: ['2001-03']\n",
            "2º trimestre 2001: ['2001-06']\n",
            "3º trimestre 2001: ['2001-09']\n",
            "4º trimestre 2001: ['2001-12']\n",
            "1º trimestre 2002: ['2002-03']\n",
            "2º trimestre 2002: ['2002-06']\n",
            "3º trimestre 2002: ['2002-09']\n",
            "4º trimestre 2002: ['2002-12']\n",
            "1º trimestre 2003: ['2003-03']\n",
            "2º trimestre 2003: ['2003-06']\n",
            "3º trimestre 2003: ['2003-09']\n",
            "4º trimestre 2003: ['2003-12']\n",
            "1º trimestre 2004: ['2004-03']\n",
            "2º trimestre 2004: ['2004-06']\n",
            "3º trimestre 2004: ['2004-09']\n",
            "4º trimestre 2004: ['2004-12']\n",
            "1º trimestre 2005: ['2005-03']\n",
            "2º trimestre 2005: ['2005-06']\n",
            "3º trimestre 2005: ['2005-09']\n",
            "4º trimestre 2005: ['2005-12']\n",
            "1º trimestre 2006: ['2006-03']\n",
            "2º trimestre 2006: ['2006-06']\n",
            "3º trimestre 2006: ['2006-09']\n",
            "4º trimestre 2006: ['2006-12']\n",
            "1º trimestre 2007: ['2007-03']\n",
            "2º trimestre 2007: ['2007-06']\n",
            "3º trimestre 2007: ['2007-09']\n",
            "4º trimestre 2007: ['2007-12']\n",
            "1º trimestre 2008: ['2008-03']\n",
            "2º trimestre 2008: ['2008-06']\n",
            "3º trimestre 2008: ['2008-09']\n",
            "4º trimestre 2008: ['2008-12']\n",
            "1º trimestre 2009: ['2009-03']\n",
            "2º trimestre 2009: ['2009-06']\n",
            "3º trimestre 2009: ['2009-09']\n",
            "4º trimestre 2009: ['2009-12']\n",
            "1º trimestre 2010: ['2010-03']\n",
            "2º trimestre 2010: ['2010-06']\n",
            "3º trimestre 2010: ['2010-09']\n",
            "4º trimestre 2010: ['2010-12']\n",
            "1º trimestre 2011: ['2011-03']\n",
            "2º trimestre 2011: ['2011-06']\n",
            "3º trimestre 2011: ['2011-09']\n",
            "4º trimestre 2011: ['2011-12']\n",
            "1º trimestre 2012: ['2012-03']\n",
            "2º trimestre 2012: ['2012-06']\n",
            "3º trimestre 2012: ['2012-09']\n",
            "4º trimestre 2012: ['2012-12']\n",
            "1º trimestre 2013: ['2013-03']\n",
            "2º trimestre 2013: ['2013-06']\n",
            "3º trimestre 2013: ['2013-09']\n",
            "4º trimestre 2013: ['2013-12']\n",
            "1º trimestre 2014: ['2014-03']\n",
            "2º trimestre 2014: ['2014-06']\n",
            "3º trimestre 2014: ['2014-09']\n",
            "4º trimestre 2014: ['2014-12']\n",
            "1º trimestre 2015: ['2015-03']\n",
            "2º trimestre 2015: ['2015-06']\n",
            "3º trimestre 2015: ['2015-09']\n",
            "4º trimestre 2015: ['2015-12']\n",
            "1º trimestre 2016: ['2016-03']\n",
            "2º trimestre 2016: ['2016-06']\n",
            "3º trimestre 2016: ['2016-09']\n",
            "4º trimestre 2016: ['2016-12']\n",
            "1º trimestre 2017: ['2017-03']\n",
            "2º trimestre 2017: ['2017-06']\n",
            "3º trimestre 2017: ['2017-09']\n",
            "4º trimestre 2017: ['2017-12']\n",
            "1º trimestre 2018: ['2018-03']\n",
            "2º trimestre 2018: ['2018-06']\n",
            "3º trimestre 2018: ['2018-09']\n",
            "4º trimestre 2018: ['2018-12']\n",
            "1º trimestre 2019: ['2019-03']\n",
            "2º trimestre 2019: ['2019-06']\n",
            "3º trimestre 2019: ['2019-09']\n",
            "4º trimestre 2019: ['2019-12']\n",
            "1º trimestre 2020: ['2020-03']\n",
            "2º trimestre 2020: ['2020-06']\n",
            "3º trimestre 2020: ['2020-09']\n",
            "4º trimestre 2020: ['2020-12']\n",
            "1º trimestre 2021: ['2021-03']\n",
            "2º trimestre 2021: ['2021-06']\n",
            "3º trimestre 2021: ['2021-09']\n",
            "4º trimestre 2021: ['2021-12']\n",
            "1º trimestre 2022: ['2022-03']\n",
            "2º trimestre 2022: ['2022-06']\n",
            "3º trimestre 2022: ['2022-09']\n",
            "4º trimestre 2022: ['2022-12']\n",
            "1º trimestre 2023: ['2023-03']\n",
            "2º trimestre 2023: ['2023-06']\n",
            "3º trimestre 2023: ['2023-09']\n",
            "4º trimestre 2023: ['2023-12']\n",
            "1º trimestre 2024: ['2024-03']\n",
            "2º trimestre 2024: ['2024-06']\n",
            "Trimestres únicos:\n",
            "['1º trimestre 1996' '2º trimestre 1996' '3º trimestre 1996'\n",
            " '4º trimestre 1996' '1º trimestre 1997' '2º trimestre 1997'\n",
            " '3º trimestre 1997' '4º trimestre 1997' '1º trimestre 1998'\n",
            " '2º trimestre 1998' '3º trimestre 1998' '4º trimestre 1998'\n",
            " '1º trimestre 1999' '2º trimestre 1999' '3º trimestre 1999'\n",
            " '4º trimestre 1999' '1º trimestre 2000' '2º trimestre 2000'\n",
            " '3º trimestre 2000' '4º trimestre 2000' '1º trimestre 2001'\n",
            " '2º trimestre 2001' '3º trimestre 2001' '4º trimestre 2001'\n",
            " '1º trimestre 2002' '2º trimestre 2002' '3º trimestre 2002'\n",
            " '4º trimestre 2002' '1º trimestre 2003' '2º trimestre 2003'\n",
            " '3º trimestre 2003' '4º trimestre 2003' '1º trimestre 2004'\n",
            " '2º trimestre 2004' '3º trimestre 2004' '4º trimestre 2004'\n",
            " '1º trimestre 2005' '2º trimestre 2005' '3º trimestre 2005'\n",
            " '4º trimestre 2005' '1º trimestre 2006' '2º trimestre 2006'\n",
            " '3º trimestre 2006' '4º trimestre 2006' '1º trimestre 2007'\n",
            " '2º trimestre 2007' '3º trimestre 2007' '4º trimestre 2007'\n",
            " '1º trimestre 2008' '2º trimestre 2008' '3º trimestre 2008'\n",
            " '4º trimestre 2008' '1º trimestre 2009' '2º trimestre 2009'\n",
            " '3º trimestre 2009' '4º trimestre 2009' '1º trimestre 2010'\n",
            " '2º trimestre 2010' '3º trimestre 2010' '4º trimestre 2010'\n",
            " '1º trimestre 2011' '2º trimestre 2011' '3º trimestre 2011'\n",
            " '4º trimestre 2011' '1º trimestre 2012' '2º trimestre 2012'\n",
            " '3º trimestre 2012' '4º trimestre 2012' '1º trimestre 2013'\n",
            " '2º trimestre 2013' '3º trimestre 2013' '4º trimestre 2013'\n",
            " '1º trimestre 2014' '2º trimestre 2014' '3º trimestre 2014'\n",
            " '4º trimestre 2014' '1º trimestre 2015' '2º trimestre 2015'\n",
            " '3º trimestre 2015' '4º trimestre 2015' '1º trimestre 2016'\n",
            " '2º trimestre 2016' '3º trimestre 2016' '4º trimestre 2016'\n",
            " '1º trimestre 2017' '2º trimestre 2017' '3º trimestre 2017'\n",
            " '4º trimestre 2017' '1º trimestre 2018' '2º trimestre 2018'\n",
            " '3º trimestre 2018' '4º trimestre 2018' '1º trimestre 2019'\n",
            " '2º trimestre 2019' '3º trimestre 2019' '4º trimestre 2019'\n",
            " '1º trimestre 2020' '2º trimestre 2020' '3º trimestre 2020'\n",
            " '4º trimestre 2020' '1º trimestre 2021' '2º trimestre 2021'\n",
            " '3º trimestre 2021' '4º trimestre 2021' '1º trimestre 2022'\n",
            " '2º trimestre 2022' '3º trimestre 2022' '4º trimestre 2022'\n",
            " '1º trimestre 2023' '2º trimestre 2023' '3º trimestre 2023'\n",
            " '4º trimestre 2023' '1º trimestre 2024' '2º trimestre 2024']\n",
            "     Ano_Mes  Valor\n",
            "0    1996-03    2.5\n",
            "1    1996-06    2.1\n",
            "2    1996-09    2.3\n",
            "3    1996-12    2.2\n",
            "4    1997-03    3.2\n",
            "..       ...    ...\n",
            "109  2023-06    3.7\n",
            "110  2023-09    3.1\n",
            "111  2023-12    2.9\n",
            "112  2024-03    2.5\n",
            "113  2024-06    2.5\n",
            "\n",
            "[114 rows x 2 columns]\n",
            "                                                Link  \\\n",
            "0  https://www.bcb.gov.br/en/publications/copommi...   \n",
            "1  https://www.bcb.gov.br/en/publications/copommi...   \n",
            "2  https://www.bcb.gov.br/en/publications/copommi...   \n",
            "3  https://www.bcb.gov.br/en/publications/copommi...   \n",
            "4  https://www.bcb.gov.br/en/publications/copommi...   \n",
            "\n",
            "                                   Texto  \\\n",
            "0  265th Meeting - September 17-18, 2024   \n",
            "1       264th Meeting - July 30-31, 2024   \n",
            "2       263rd Meeting - June 18-19, 2024   \n",
            "3          262nd Meeting - May 7-8, 2024   \n",
            "4      261st Meeting - March 19-20, 2024   \n",
            "\n",
            "                                    Link de Download  \\\n",
            "0  https://www.bcb.gov.br/content/copom/copomminu...   \n",
            "1  https://www.bcb.gov.br/content/copom/copomminu...   \n",
            "2  https://www.bcb.gov.br/content/copom/copomminu...   \n",
            "3  https://www.bcb.gov.br/content/copom/copomminu...   \n",
            "4  https://www.bcb.gov.br/content/copom/copomminu...   \n",
            "\n",
            "                                        Texto do PDF  \\\n",
            "0  1 bcb.gov.br Minutes of the Meeting of the Mon...   \n",
            "1  1 bcb.gov.br Minutes of the Meeting of the Mon...   \n",
            "2  1 bcb.gov.br Minutes of the Meeting of the Mon...   \n",
            "3  1 bcb.gov.br Minutes of the Meeting of the Mon...   \n",
            "4  1 bcb.gov.br Minutes of the Meeting of the Mon...   \n",
            "\n",
            "                                    Texto Processado  Ano_Mes  \\\n",
            "0  a) update economic outlook copoms scenario glo...  2024-09   \n",
            "1  a) update economic outlook copoms scenario glo...  2024-07   \n",
            "2  a) update economic outlook copoms scenario glo...  2024-06   \n",
            "3  a) update economic outlook copoms scenario glo...  2024-05   \n",
            "4  a) update economic outlook copoms scenario glo...  2024-03   \n",
            "\n",
            "                                                   A  \\\n",
            "0  a) update economic outlook copoms scenario glo...   \n",
            "1  a) update economic outlook copoms scenario glo...   \n",
            "2  a) update economic outlook copoms scenario glo...   \n",
            "3  a) update economic outlook copoms scenario glo...   \n",
            "4  a) update economic outlook copoms scenario glo...   \n",
            "\n",
            "                                                   B  \\\n",
            "0  b) scenarios risk analysis reference scenario ...   \n",
            "1  b) scenarios risk analysis reference scenario ...   \n",
            "2  b) scenarios risk analysis reference scenario ...   \n",
            "3  b) scenarios risk analysis reference scenario ...   \n",
            "4  b) scenarios risk analysis baseline scenario i...   \n",
            "\n",
            "                                                   C  \\\n",
            "0  c) discussion conduct monetary policy discusse...   \n",
            "1  c) discussion conduct monetary policy discusse...   \n",
            "2  c) discussion conduct monetary policy discusse...   \n",
            "3  c) discussion conduct monetary policy discusse...   \n",
            "4  c) discussion conduct monetary policy discusse...   \n",
            "\n",
            "                                                   D Footnotes  \n",
            "0  d) monetary policy decision scenario marked re...       NaN  \n",
            "1  d) monetary policy decision considering evolut...       NaN  \n",
            "2  d) monetary policy decision considering evolut...       NaN  \n",
            "3  d) monetary policy decision considering evolut...       NaN  \n",
            "4  d) monetary policy decision considering evolut...       NaN  \n",
            "                                                 Link  \\\n",
            "24  https://www.bcb.gov.br/en/publications/copommi...   \n",
            "25  https://www.bcb.gov.br/en/publications/copommi...   \n",
            "26  https://www.bcb.gov.br/en/publications/copommi...   \n",
            "27  https://www.bcb.gov.br/en/publications/copommi...   \n",
            "28  https://www.bcb.gov.br/en/publications/copommi...   \n",
            "\n",
            "                                 Texto  \\\n",
            "24   66th Copom minutes - January 2002   \n",
            "25  67th Copom minutes - February 2002   \n",
            "26     68th Copom minutes - March 2002   \n",
            "27     70th Copom minutes - April 2002   \n",
            "28     69th Copom minutes - April 2002   \n",
            "\n",
            "                                     Link de Download  \\\n",
            "24  https://www.bcb.gov.br/content/copom/copomminu...   \n",
            "25  https://www.bcb.gov.br/content/copom/copomminu...   \n",
            "26  https://www.bcb.gov.br/content/copom/copomminu...   \n",
            "27  https://www.bcb.gov.br/content/copom/copomminu...   \n",
            "28  https://www.bcb.gov.br/content/copom/copomminu...   \n",
            "\n",
            "                                         Texto do PDF  \\\n",
            "24  January 3rd, 2002 MINUTES OF THE 66th MEETING ...   \n",
            "25  February 4th, 2002 MINUTES OF THE 67th MEETING...   \n",
            "26  March 4th, 2002 MINUTES OF THE 68th MEETING OF...   \n",
            "27  April 29th, 2002 MINUTES OF THE 70th MEETING O...   \n",
            "28  Information for unrestricted disclosure. It is...   \n",
            "\n",
            "                                     Texto Processado  Ano_Mes    A    B    C  \\\n",
            "24  rd meeting banco central brasil monetary polic...  2002-01  NaN  NaN  NaN   \n",
            "25  meeting banco central brasil monetary policy c...  2002-02  NaN  NaN  NaN   \n",
            "26  meeting banco central brasil monetary policy c...  2002-03  NaN  NaN  NaN   \n",
            "27  meeting banco central brasil monetary policy c...  2002-04  NaN  NaN  NaN   \n",
            "28  information unrestricted disclosure intended b...  2002-04  NaN  NaN  NaN   \n",
            "\n",
            "      D Footnotes  Valor  \n",
            "24  NaN       NaN    NaN  \n",
            "25  NaN       NaN    NaN  \n",
            "26  NaN       NaN    0.7  \n",
            "27  NaN       NaN    NaN  \n",
            "28  NaN       NaN    NaN  \n"
          ]
        }
      ],
      "source": [
        "# https://www.ibge.gov.br/estatisticas/economicas/contas-nacionais/9300-contas-nacionais-trimestrais.html?=&t=series-historicas&utm_source=landing&utm_medium=explica&utm_campaign=pib#evolucao-taxa\n",
        "\n",
        "# Fazendo upload do arquivo CSV\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Carregar o arquivo CSV usando o delimitador correto\n",
        "df_trimestres = pd.read_csv('pib_trimestral.csv', delimiter=';', header=1)  # O cabeçalho correto\n",
        "\n",
        "# Excluir a primeira coluna se necessário (baseado no que você descreveu)\n",
        "df_trimestres = df_trimestres.iloc[:1, 1:]  # Remove a primeira coluna\n",
        "\n",
        "\n",
        "# Verifique o DataFrame após as alterações\n",
        "print(\"DataFrame após a leitura:\")\n",
        "print(df_trimestres.head())\n",
        "\n",
        "# Agora, precisamos reorganizar os dados\n",
        "# Vamos usar melt para transformar os dados\n",
        "df_trimestres_melted = df_trimestres.melt(var_name='Trimestre', value_name='Valor')\n",
        "\n",
        "# Verifique o DataFrame derretido\n",
        "print(\"DataFrame derretido:\")\n",
        "print(df_trimestres_melted.head())\n",
        "\n",
        "# Função para gerar mapeamento de trimestres\n",
        "def gerar_mapeamento_trimestres(inicio_ano, fim_ano):\n",
        "    mapeamento = {}\n",
        "    for ano in range(inicio_ano, fim_ano + 1):\n",
        "        for trimestre in range(1, 5):\n",
        "            mes = trimestre * 3  # 1: Março, 2: Junho, 3: Setembro, 4: Dezembro\n",
        "            ano_mes = f\"{ano}-{mes:02d}\"\n",
        "            mapeamento[f\"{trimestre}º trimestre {ano}\"] = ano_mes\n",
        "    return mapeamento\n",
        "\n",
        "# Gerar mapeamento de 1996 a 2024\n",
        "mapeamento_trimestre = gerar_mapeamento_trimestres(1996, 2024)\n",
        "df_trimestres_melted['Ano_Mes'] = df_trimestres_melted['Trimestre'].map(mapeamento_trimestre)\n",
        "\n",
        "print(\"DataFrame com o mapeamento:\")\n",
        "print(df_trimestres_melted[['Trimestre', 'Ano_Mes']].head(20))  # Exibir as primeiras 20 linhas\n",
        "\n",
        "# Verificar se há valores ausentes na coluna Ano_Mes\n",
        "valores_ausentes = df_trimestres_melted['Ano_Mes'].isna().sum()\n",
        "print(f\"Número de valores ausentes em 'Ano_Mes': {valores_ausentes}\")\n",
        "\n",
        "# Exibir trimestres e seus respectivos Ano_Mes\n",
        "for trimestre in df_trimestres_melted['Trimestre'].unique():\n",
        "    print(f\"{trimestre}: {df_trimestres_melted[df_trimestres_melted['Trimestre'] == trimestre]['Ano_Mes'].values}\")\n",
        "\n",
        "\n",
        "# Verifique o resultado do mapeamento\n",
        "print(\"Trimestres únicos:\")\n",
        "print(df_trimestres_melted['Trimestre'].unique())\n",
        "print(df_trimestres_melted[['Ano_Mes', 'Valor']])\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "# Agora, mescle os dois dataframes (supondo que o df original esteja carregado em df)\n",
        "df_final = pd.merge(df, df_trimestres_melted[['Ano_Mes', 'Valor']], on='Ano_Mes', how='outer')\n",
        "df_final = df_final.dropna(subset=['Texto Processado'])\n",
        "\n",
        "# Verifique o resultado final\n",
        "print(df_final.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3elGo5vXpTg"
      },
      "source": [
        "Treinando o modelo Word2vec. Utilizando o Texto Processado como corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "M4ONo7dRXya2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00f8ab7c-ad2a-4bcc-d2a0-bd76a2a62930"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treinando Word2Vec...\n"
          ]
        }
      ],
      "source": [
        "# Carregar o CSV (Para nao precisar rodar tudo novamente)\n",
        "#df = pd.read_csv('seu_arquivo.csv')  # Substitua pelo caminho do seu arquivo\n",
        "# Extraindo a quarta coluna como corpus\n",
        "#corpus = df.iloc[:, 3].tolist()  # Altere o índice se necessário\n",
        "\n",
        "# Extraindo a quarta coluna como corpus\n",
        "corpus = df['Texto Processado'].tolist()  # Altere o índice se necessário\n",
        "\n",
        "# Pré-processamento do texto (divisão em palavras)\n",
        "# Aqui estamos usando um simples split, mas você pode querer fazer mais pré-processamento\n",
        "corpus_tokenized = [text.split() for text in corpus]\n",
        "\n",
        "# Word2Vec (cbow)\n",
        "print(\"Treinando Word2Vec...\")\n",
        "word2vec_model = gensim.models.Word2Vec(corpus_tokenized, vector_size=100, window=5, min_count=1, workers=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siTEycAE9yWV"
      },
      "source": [
        "Criando o vetor medio dos vetores medios das atas referente ao trimestre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "0tIViDeC9y6Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7e5af5f-744f-492c-bc03-67cc3b5ec25a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                     Texto Processado  Valor  \\\n",
            "24  rd meeting banco central brasil monetary polic...    NaN   \n",
            "25  meeting banco central brasil monetary policy c...    NaN   \n",
            "26  meeting banco central brasil monetary policy c...    0.7   \n",
            "27  meeting banco central brasil monetary policy c...    NaN   \n",
            "28  information unrestricted disclosure intended b...    NaN   \n",
            "29  nd meeting banco central brasil (bcb) monetary...    0.7   \n",
            "30  information unrestricted disclosure intended b...    0.7   \n",
            "31  july rd meeting banco central brasil (bcb) mon...    NaN   \n",
            "32  banco central brasil (bcb) meeting monetary po...    NaN   \n",
            "33  banco central brasil (bcb) meeting monetary po...    1.6   \n",
            "34  st banco central brasil (bcb) meeting monetary...    NaN   \n",
            "35  banco central brasil (bcb) meeting monetary po...    NaN   \n",
            "36  banco central brasil (bcb) meeting monetary po...    NaN   \n",
            "37  banco central brasil (bcb) meeting monetary po...    3.1   \n",
            "38  banco central brasil meeting monetary policy c...    NaN   \n",
            "39  st meeting monetary policy committee (copom) d...    NaN   \n",
            "40  nd meeting monetary policy committee (copom) d...    3.6   \n",
            "41  recent evolution inflation consumer price infl...    NaN   \n",
            "42  recent evolution inflation measures inflation ...    NaN   \n",
            "43  recent evolution inflation measures inflation ...    3.2   \n",
            "\n",
            "                                          Vetor Médio  \\\n",
            "24  [0.017652594, 0.142689, 0.05446406, 0.09958483...   \n",
            "25  [0.022904072, 0.14705509, 0.057849985, 0.10575...   \n",
            "26  [0.03105631, 0.14177704, 0.054904584, 0.099885...   \n",
            "27  [0.02795132, 0.15423837, 0.05956144, 0.1041139...   \n",
            "28  [0.028245449, 0.14578825, 0.058531035, 0.10440...   \n",
            "29  [0.03205173, 0.14639015, 0.053189848, 0.113059...   \n",
            "30  [0.03285405, 0.14784393, 0.058232117, 0.108521...   \n",
            "31  [0.034110222, 0.14812827, 0.055145733, 0.10682...   \n",
            "32  [0.027728995, 0.14621057, 0.049770903, 0.10593...   \n",
            "33  [0.02225835, 0.14315887, 0.05148129, 0.1060786...   \n",
            "34  [0.027612241, 0.13838604, 0.062006697, 0.11133...   \n",
            "35  [0.057316527, 0.09635933, 0.03416913, 0.093601...   \n",
            "36  [0.023641232, 0.14577647, 0.057269994, 0.10752...   \n",
            "37  [0.022238366, 0.1474283, 0.06183813, 0.1085447...   \n",
            "38  [0.01577544, 0.13191502, 0.06826694, 0.0977752...   \n",
            "39  [0.022702426, 0.14161453, 0.074000984, 0.09875...   \n",
            "40  [0.026369464, 0.141571, 0.07153905, 0.11196663...   \n",
            "41  [0.024971973, 0.14963314, 0.07781884, 0.117092...   \n",
            "42  [0.021611238, 0.16163306, 0.07438818, 0.120309...   \n",
            "43  [0.024152214, 0.15760218, 0.075984456, 0.12066...   \n",
            "\n",
            "                                vetor_medio_trimestre  \n",
            "24                                               None  \n",
            "25                                               None  \n",
            "26  [0.025667321, 0.14332454, 0.0555308, 0.1012784...  \n",
            "27                                               None  \n",
            "28                                               None  \n",
            "29  [0.030075058, 0.14820173, 0.05611804, 0.108659...  \n",
            "30  [0.03285405, 0.14784393, 0.058232117, 0.108521...  \n",
            "31                                               None  \n",
            "32                                               None  \n",
            "33  [0.02658898, 0.14516413, 0.051969804, 0.106227...  \n",
            "34                                               None  \n",
            "35                                               None  \n",
            "36                                               None  \n",
            "37  [0.029214183, 0.13713446, 0.05649337, 0.106348...  \n",
            "38                                               None  \n",
            "39                                               None  \n",
            "40  [0.022804199, 0.13916788, 0.07133651, 0.105115...  \n",
            "41                                               None  \n",
            "42                                               None  \n",
            "43  [0.023721911, 0.15661764, 0.07604398, 0.119682...  \n"
          ]
        }
      ],
      "source": [
        "# Função para obter o vetor médio\n",
        "def get_average_vector(text):\n",
        "    words = text.split()\n",
        "    word_vectors = [word2vec_model.wv[word] for word in words if word in word2vec_model.wv]\n",
        "    if word_vectors:\n",
        "        return np.mean(word_vectors, axis=0)\n",
        "    else:\n",
        "        return np.zeros(word2vec_model.vector_size)  # Retorna vetor zero se não houver palavras válidas\n",
        "\n",
        "# Criar a nova coluna 'Texto Processado'\n",
        "df_final['Vetor Médio'] = df_final['Texto Processado'].apply(get_average_vector)\n",
        "\n",
        "# Inicializa uma lista para os vetores médios do trimestre\n",
        "vetores_medio_trimeste = []\n",
        "previous_vectors = []  # Lista para acumular vetores das linhas com valor missing\n",
        "\n",
        "# Para cada linha no DataFrame\n",
        "for i in range(len(df_final)):\n",
        "    # Se o valor não for missing\n",
        "    if not np.isnan(df_final['Valor'].iloc[i]):\n",
        "        # Se houver vetores acumulados, calcula a média\n",
        "        if previous_vectors:\n",
        "            vetor_medio_acumulado = np.mean(previous_vectors, axis=0)\n",
        "            # Calcula a média entre o vetor acumulado e o vetor atual\n",
        "            vetor_medio_final = np.mean([vetor_medio_acumulado, df_final['Vetor Médio'].iloc[i]], axis=0)\n",
        "            vetores_medio_trimeste.append(vetor_medio_final)\n",
        "        else:\n",
        "            # Caso não haja vetores acumulados, apenas adiciona o vetor atual\n",
        "            vetores_medio_trimeste.append(df_final['Vetor Médio'].iloc[i])\n",
        "\n",
        "        # Limpa a lista acumulada para o próximo conjunto\n",
        "        previous_vectors = []\n",
        "    else:\n",
        "        # Se o valor for missing, acumula o vetor médio\n",
        "        previous_vectors.append(df_final['Vetor Médio'].iloc[i])\n",
        "        vetores_medio_trimeste.append(None)  # Adiciona None para os missing\n",
        "\n",
        "# Adiciona a nova coluna ao DataFrame\n",
        "df_final['vetor_medio_trimestre'] = vetores_medio_trimeste\n",
        "\n",
        "# Verifica o resultado\n",
        "print(df_final[['Texto Processado', 'Valor', 'Vetor Médio', 'vetor_medio_trimestre']].head(20))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GX_7-qp6DXY6"
      },
      "source": [
        "Previsao"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JRltligzDZy5",
        "outputId": "48a8b1da-24fc-495c-ecff-88fbd1725318"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 3.2633877   3.3016148   6.26202    -0.2717247   1.7239513   5.4998417\n",
            "  4.5408688   5.838331    4.886341    5.2608852   5.6140385   4.382736\n",
            "  2.7309132  -1.8716412   0.84503174  5.2882595  -3.4165096   1.7729893\n",
            "  4.46159     2.5309525   1.7208157   5.0216293   4.8089848 ]\n",
            "    Valor Real  Previsão\n",
            "0          3.1  3.263388\n",
            "1          4.8  3.301615\n",
            "2          4.2  6.262020\n",
            "3          0.7 -0.271725\n",
            "4         -1.2  1.723951\n",
            "5          2.5  5.499842\n",
            "6          2.8  4.540869\n",
            "7          6.6  5.838331\n",
            "8          5.8  4.886341\n",
            "9          1.2  5.260885\n",
            "10         2.7  5.614038\n",
            "11         5.3  4.382736\n",
            "12         1.4  2.730913\n",
            "13        -4.5 -1.871641\n",
            "14         3.6  0.845032\n",
            "15         6.3  5.288260\n",
            "16        -1.7 -3.416510\n",
            "17         2.0  1.772989\n",
            "18         7.5  4.461590\n",
            "19         1.2  2.530952\n",
            "20         3.1  1.720816\n",
            "21         3.2  5.021629\n",
            "22         5.6  4.808985\n",
            "Mean Squared Error: 4.018541577572664\n",
            "Mean Squared Error AR2: 8.130902685223948\n"
          ]
        }
      ],
      "source": [
        "# Descartar as observações onde a coluna 'Valor' é missing (NaN)\n",
        "df_final_cleaned = df_final.dropna(subset=['Valor'])\n",
        "\n",
        "# Verificar o resultado\n",
        "#print(df_final_cleaned.head())  # Exibe as primeiras linhas do DataFrame limpo\n",
        "\n",
        "# Calcular o vetor médio para cada texto processado\n",
        "X = np.array([get_average_vector(text) for text in df_final_cleaned['Texto Processado']])\n",
        "\n",
        "# Y: Valores a serem previstos\n",
        "y = df_final_cleaned['Valor'].values\n",
        "\n",
        "# Dividir os dados em conjuntos de treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Treinando o modelo de regressão\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Fazer previsões\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Verificar as previsões\n",
        "print(predictions)\n",
        "\n",
        "# Criar um DataFrame para comparar previsões e valores reais\n",
        "results_df = pd.DataFrame({\n",
        "    'Valor Real': y_test,\n",
        "    'Previsão': predictions\n",
        "})\n",
        "\n",
        "# Verificar os resultados\n",
        "print(results_df)\n",
        "\n",
        "# Calcular o erro médio quadrático (MSE)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "\n",
        "# Imprimir o MSE\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "\n",
        "# Ajustar um modelo autoregressivo (AR) usando apenas y\n",
        "model_ar2 = AutoReg(y_train, lags=1)  # Use o número de lags apropriado\n",
        "model_fit_ar2 = model_ar2.fit()\n",
        "\n",
        "# Fazer previsões\n",
        "predictions_ar2 = model_fit_ar2.predict(start=len(y_train), end=len(y_train) + len(y_test) - 1)\n",
        "\n",
        "# Calcular o erro médio quadrático (MSE)\n",
        "mse_ar2 = mean_squared_error(y_test, predictions_ar2)\n",
        "\n",
        "# Imprimir o MSE\n",
        "print(f'Mean Squared Error AR2: {mse_ar2}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "YUrlrSVAKIAv",
        "outputId": "4d11dff4-c046-4c8f-b1b0-9d90d34e92c4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1aee357b-5003-45a7-a321-6b630494c729\", \"dados_extraidos.csv\", 12079570)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#exportando para um arquivo csv\n",
        "\n",
        "output_csv = 'dados_extraidos.csv'  # Nome do arquivo CSV\n",
        "df_final.to_csv(output_csv, index=False)\n",
        "\n",
        "# Se você estiver usando Google Colab, faça o download do arquivo CSV\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download(output_csv)\n",
        "except ImportError:\n",
        "    print(\"Não é um ambiente Colab. O arquivo está salvo como:\", output_csv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5GbV214Re_H"
      },
      "source": [
        "--------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sintonia fina de base pre treinada"
      ],
      "metadata": {
        "id": "QDA5PZlBYj-E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDCTZZHnXG7w",
        "outputId": "6b6f4c48-b78d-4604-a361-ce9460aa26ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2376512, 2650340)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "import numpy as np\n",
        "from gensim.models import KeyedVectors, Word2Vec\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Defina o caminho para os embeddings\n",
        "embeddings_path = '/content/drive/My Drive/Caen/TESE/word2vec-google-news-300.model.vectors.npy'\n",
        "\n",
        "# Carregar os vetores\n",
        "vectors = np.load(embeddings_path)\n",
        "\n",
        "# Tokenizar cada frase do seu DataFrame\n",
        "corpus = df['Texto Processado'].tolist()\n",
        "tokenized_corpus = [sentence.split() for sentence in corpus]  # Tokenização simples\n",
        "\n",
        "# Criar um novo modelo Word2Vec\n",
        "word2vec_model = Word2Vec(vector_size=300, window=5, min_count=1, sg=1)\n",
        "\n",
        "# Construir o vocabulário do corpus\n",
        "word2vec_model.build_vocab(tokenized_corpus)\n",
        "\n",
        "# Inicializar os vetores do novo modelo com os vetores pré-treinados\n",
        "for word in word2vec_model.wv.index_to_key:\n",
        "    if word in vectors:  # Verifique se a palavra existe nos vetores\n",
        "        word2vec_model.wv[word] = vectors[vectors.index(word)]  # Atribua o vetor pré-treinado\n",
        "\n",
        "# Treinar o modelo no seu conjunto de dados\n",
        "word2vec_model.train(tokenized_corpus, total_examples=len(tokenized_corpus), epochs=new_model.epochs)\n",
        "\n",
        "# Salvar o novo modelo\n",
        "word2vec_model.save(\"/content/drive/My Drive/Caen/TESE/meu_modelo_fine_tuned_word2vec.model\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_nXj23Mrm7f"
      },
      "source": [
        "sintonia fina do w2vec a partir de uma base pre treinada(ainda nao funciona!!!)\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sintonia fina partindo do modelo pre treinado\n",
        "import numpy as np\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Defina o caminho para o modelo pré-treinado\n",
        "model_path = '/content/drive/My Drive/Caen/TESE/word2vec-google-news-300.model'\n",
        "\n",
        "# Carregar o modelo Word2Vec pré-treinado\n",
        "pretrained_model = Word2Vec.load(model_path)\n",
        "\n",
        "# Tokenizar cada frase do seu DataFrame\n",
        "corpus = df['Texto Processado'].tolist()\n",
        "tokenized_corpus = [sentence.split() for sentence in corpus]  # Tokenização simples\n",
        "\n",
        "# Atualizar o vocabulário do modelo pré-treinado com seu corpus\n",
        "pretrained_model.build_vocab(tokenized_corpus, update=True)\n",
        "\n",
        "# Treinar o modelo com seu corpus\n",
        "pretrained_model.train(tokenized_corpus, total_examples=len(tokenized_corpus), epochs=pretrained_model.epochs)\n",
        "\n",
        "# Salvar o novo modelo ajustado\n",
        "#pretrained_model.save(\"/content/drive/My Drive/Caen/TESE/meu_modelo_fine_tuned_word2vec.model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "Mln7aaKhOQVo",
        "outputId": "27ad69b0-e453-4da6-cd67-fa04e41de8df"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "Model of type <class 'gensim.models.keyedvectors.KeyedVectors'> can't be loaded by <class 'gensim.models.word2vec.Word2Vec'>",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e5ec24bdea69>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Carregar o modelo Word2Vec pré-treinado\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mpretrained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Tokenizar cada frase do seu DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, rethrow, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mae\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrethrow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mae\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1961\u001b[0m             logger.error(\n\u001b[1;32m   1962\u001b[0m                 \u001b[0;34m\"Model load error. Was model saved using code from an older Gensim Version? \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, rethrow, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1954\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1955\u001b[0m                 \u001b[0mrethrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1956\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model of type %s can't be loaded by %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1957\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1958\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mae\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: Model of type <class 'gensim.models.keyedvectors.KeyedVectors'> can't be loaded by <class 'gensim.models.word2vec.Word2Vec'>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "# Listar arquivos no diretório onde o arquivo deveria estar\n",
        "print(os.listdir('/content/drive/My Drive/Caen/TESE'))\n",
        "\n",
        "# Defina o caminho para o arquivo no Google Drive\n",
        "embeddings_path = '/content/drive/My Drive/Caen/TESE/word2vec-google-news-300.model.vectors.npy'\n",
        "embeddings = np.load(embeddings_path)\n",
        "\n",
        "# Carregar os tokens\n",
        "tokens_path = '/content/drive/My Drive/Caen/TESE/word2vec-google-news-300.model.vectors.txt'\n",
        "with open(tokens_path) as fp:\n",
        "    tokens = [line.strip() for line in fp]\n",
        "\n",
        "# Acessar o embedding da palavra 'hello'\n",
        "if 'hello' in tokens:\n",
        "    hello_embedding = embeddings[tokens.index('hello')]\n",
        "    print(hello_embedding)\n",
        "else:\n",
        "    print(\"A palavra 'hello' não está nos tokens.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "ttJwTi1tDSiO",
        "outputId": "7d94cf09-56a7-4cd8-ab98-1ddb594a6fa6"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "['tese PyMuPDF.ipynb', 'Antigos', 'word2vec-google-news-300.model.vectors.npy', 'Untitled0.ipynb', 'Proximos passos.gdoc']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/My Drive/Caen/TESE/word2vec-google-news-300.model.vectors.txt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-1daa8e91ed85>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Carregar os tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mtokens_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/My Drive/Caen/TESE/word2vec-google-news-300.model.vectors.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/Caen/TESE/word2vec-google-news-300.model.vectors.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "iXMVY_XIrh9d",
        "outputId": "3cd2f992-584e-4d05-a961-ab0a883cad6f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-398e07f3-4767-4c98-88a6-8ad4e72415f6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-398e07f3-4767-4c98-88a6-8ad4e72415f6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-293a735e76d5>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Faça o upload do arquivo .npy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Carregar o arquivo .npy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvectors_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'word2vec-google-news-300.model.vectors.npy'\u001b[0m  \u001b[0;31m# Altere se necessário\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m   \"\"\"\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m   \u001b[0;31m# First result is always an indication that the file picker has completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m   result = _output.eval_js(\n\u001b[0m\u001b[1;32m    157\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[1;32m    158\u001b[0m           \u001b[0minput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Faça o upload do arquivo .npy\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Carregar o arquivo .npy\n",
        "vectors_path = 'word2vec-google-news-300.model.vectors.npy'  # Altere se necessário\n",
        "vectors = np.load(vectors_path)\n",
        "\n",
        "# Carregar as palavras associadas\n",
        "words_path = 'path/to/word2vec-google-news-300.model.vectors.words'  # Altere conforme necessário\n",
        "with open(words_path, 'r', encoding='utf-8') as f:\n",
        "    words = f.read().splitlines()\n",
        "\n",
        "# Extraindo a coluna como corpus\n",
        "corpus = df['Texto Processado'].tolist()\n",
        "\n",
        "# Supondo que o corpus seja uma lista de strings, tokenize cada frase\n",
        "tokenized_corpus = [sentence.split() for sentence in corpus]  # Tokenização simples\n",
        "\n",
        "#Criar um modelo KeyedVectors\n",
        "word2vec_model = KeyedVectors(vector_size=300)\n",
        "word2vec_model.add_vectors(words, vectors)\n",
        "\n",
        "# Criar um novo modelo Word2Vec e transferir pesos\n",
        "new_model = Word2Vec(tokenized_corpus, vector_size=300, window=5, min_count=1, sg=1)\n",
        "\n",
        "# Inicializar os pesos do modelo com os vetores pré-treinados\n",
        "for word in word2vec_model.key_to_index:\n",
        "    if word in new_model.wv.key_to_index:\n",
        "        new_model.wv[word] = word2vec_model[word]\n",
        "\n",
        "# Treinar o modelo no seu conjunto de dados\n",
        "new_model.train(tokenized_corpus, total_examples=len(tokenized_corpus), epochs=new_model.epochs)\n",
        "\n",
        "# Salvar o novo modelo\n",
        "new_model.save(\"meu_modelo_fine_tuned_word2vec.model\")\n",
        "\n",
        "files.download(\"meu_modelo_fine_tuned_word2vec.model\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}