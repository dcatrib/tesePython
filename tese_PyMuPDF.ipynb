{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dcatrib/tesePython/blob/main/tese_PyMuPDF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "id": "KLlzG5xH9C2Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9be8b182-c550-46d6-d854-b567ac4aa41c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyMuPDF\n",
            "  Downloading PyMuPDF-1.24.11-cp38-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Collecting selenium\n",
            "  Downloading selenium-4.25.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting chromedriver-autoinstaller\n",
            "  Downloading chromedriver_autoinstaller-0.6.4-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Collecting trio~=0.17 (from selenium)\n",
            "  Downloading trio-0.26.2-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting trio-websocket~=0.9 (from selenium)\n",
            "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.10/dist-packages (from selenium) (4.12.2)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.10/dist-packages (from chromedriver-autoinstaller) (24.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (24.2.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Collecting outcome (from trio~=0.17->selenium)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.2.2)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Downloading PyMuPDF-1.24.11-cp38-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (19.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.6/19.6 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading selenium-4.25.0-py3-none-any.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chromedriver_autoinstaller-0.6.4-py3-none-any.whl (7.6 kB)\n",
            "Downloading trio-0.26.2-py3-none-any.whl (475 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m476.0/476.0 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
            "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDF, outcome, h11, chromedriver-autoinstaller, wsproto, trio, trio-websocket, selenium\n",
            "Successfully installed PyMuPDF-1.24.11 chromedriver-autoinstaller-0.6.4 h11-0.14.0 outcome-1.3.0.post0 selenium-4.25.0 trio-0.26.2 trio-websocket-0.11.1 wsproto-1.2.0\n",
            "Get:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:6 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,160 kB]\n",
            "Get:7 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,325 kB]\n",
            "Get:8 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,122 kB]\n",
            "Ign:9 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Get:10 https://r2u.stat.illinois.edu/ubuntu jammy Release [5,713 B]\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy Release.gpg [793 B]\n",
            "Get:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,031 kB]\n",
            "Hit:14 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:15 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:16 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,448 kB]\n",
            "Get:18 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,592 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,200 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,602 kB]\n",
            "Get:21 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,379 kB]\n",
            "Fetched 26.1 MB in 3s (7,920 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "wget is already the newest version (1.21.2-2ubuntu1.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "--2024-10-10 17:02:59--  https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
            "Resolving dl.google.com (dl.google.com)... 142.250.153.93, 142.250.153.136, 142.250.153.91, ...\n",
            "Connecting to dl.google.com (dl.google.com)|142.250.153.93|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 110925276 (106M) [application/x-debian-package]\n",
            "Saving to: ‘google-chrome-stable_current_amd64.deb’\n",
            "\n",
            "google-chrome-stabl 100%[===================>] 105.79M   334MB/s    in 0.3s    \n",
            "\n",
            "2024-10-10 17:03:00 (334 MB/s) - ‘google-chrome-stable_current_amd64.deb’ saved [110925276/110925276]\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Note, selecting 'google-chrome-stable' instead of './google-chrome-stable_current_amd64.deb'\n",
            "The following additional packages will be installed:\n",
            "  libvulkan1 mesa-vulkan-drivers\n",
            "The following NEW packages will be installed:\n",
            "  google-chrome-stable libvulkan1 mesa-vulkan-drivers\n",
            "0 upgraded, 3 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 10.9 MB/122 MB of archives.\n",
            "After this operation, 413 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libvulkan1 amd64 1.3.204.1-2 [128 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 mesa-vulkan-drivers amd64 23.2.1-1ubuntu3.1~22.04.2 [10.7 MB]\n",
            "Get:3 /content/google-chrome-stable_current_amd64.deb google-chrome-stable amd64 129.0.6668.100-1 [111 MB]\n",
            "Fetched 10.9 MB in 1s (8,952 kB/s)\n",
            "Selecting previously unselected package libvulkan1:amd64.\n",
            "(Reading database ... 123621 files and directories currently installed.)\n",
            "Preparing to unpack .../libvulkan1_1.3.204.1-2_amd64.deb ...\n",
            "Unpacking libvulkan1:amd64 (1.3.204.1-2) ...\n",
            "Selecting previously unselected package google-chrome-stable.\n",
            "Preparing to unpack .../google-chrome-stable_current_amd64.deb ...\n",
            "Unpacking google-chrome-stable (129.0.6668.100-1) ...\n",
            "Selecting previously unselected package mesa-vulkan-drivers:amd64.\n",
            "Preparing to unpack .../mesa-vulkan-drivers_23.2.1-1ubuntu3.1~22.04.2_amd64.deb ...\n",
            "Unpacking mesa-vulkan-drivers:amd64 (23.2.1-1ubuntu3.1~22.04.2) ...\n",
            "Setting up libvulkan1:amd64 (1.3.204.1-2) ...\n",
            "Setting up mesa-vulkan-drivers:amd64 (23.2.1-1ubuntu3.1~22.04.2) ...\n",
            "Setting up google-chrome-stable (129.0.6668.100-1) ...\n",
            "update-alternatives: using /usr/bin/google-chrome-stable to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/google-chrome-stable to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/google-chrome-stable to provide /usr/bin/google-chrome (google-chrome) in auto mode\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install PyMuPDF requests selenium chromedriver-autoinstaller pandas nltk gensim numpy\n",
        "\n",
        "!apt-get update\n",
        "!apt-get install -y wget\n",
        "!wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
        "!apt-get install -y ./google-chrome-stable_current_amd64.deb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "id": "AyVkOEFexu7A"
      },
      "outputs": [],
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.common.exceptions import NoSuchElementException, TimeoutException, StaleElementReferenceException\n",
        "import chromedriver_autoinstaller\n",
        "import requests\n",
        "import fitz\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "from gensim.models import KeyedVectors, Word2Vec\n",
        "import gensim\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from statsmodels.tsa.ar_model import AutoReg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "collapsed": true,
        "id": "MqPHOhrtxvNR",
        "outputId": "36f36cf5-49be-4e11-d234-17f54a3de7bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/usr/local/lib/python3.10/dist-packages/chromedriver_autoinstaller/129/chromedriver'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Configurando o WebDriver\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "\n",
        "# Instala automaticamente a versão correta do ChromeDriver\n",
        "chromedriver_autoinstaller.install()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "N6MM2g-p7BdE"
      },
      "outputs": [],
      "source": [
        "# URL para scrape\n",
        "url = \"https://www.bcb.gov.br/en/publications/copomminutes/cronologicos\"\n",
        "\n",
        "# Criar uma nova instância do Chrome driver\n",
        "driver = webdriver.Chrome(options=chrome_options)\n",
        "driver.get(url)\n",
        "\n",
        "# Esperar o seletor específico estar presente\n",
        "WebDriverWait(driver, 15).until(\n",
        "    EC.presence_of_element_located((By.CSS_SELECTOR, 'body > app-root > app-root > main > dynamic-comp > div > div > bcb-publicacao > div > div > bcb-ultimaspublicacoes > div'))\n",
        ")\n",
        "\n",
        "# Definir o seletor\n",
        "selector = 'body > app-root > app-root > main > dynamic-comp > div > div > bcb-publicacao > div > div > bcb-ultimaspublicacoes > div'\n",
        "\n",
        "# Lista para armazenar hrefs, textos e links de download\n",
        "hrefs_and_texts = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "uXBHUR-O7HRi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86eda6b4-5e7d-4391-c5b3-a7653f00383b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n"
          ]
        }
      ],
      "source": [
        "# Função para recuperar links e botões de download\n",
        "def retrieve_links():\n",
        "    try:\n",
        "        elements = driver.find_elements(By.CSS_SELECTOR, selector)\n",
        "        link_count = 0  # Inicializa um contador para os links\n",
        "        for element in elements:\n",
        "            links = element.find_elements(By.TAG_NAME, 'a')\n",
        "            for link in links:\n",
        "                if link_count >= 183:  # Limita a 50 links\n",
        "                    return  # Sai da função se 50 links foram processados\n",
        "                href = link.get_attribute('href')\n",
        "                text = link.text\n",
        "                if href and text and text[0].isdigit():\n",
        "                    driver.get(href)\n",
        "                    # Esperar o botão de download\n",
        "                    try:\n",
        "                        download_button = WebDriverWait(driver, 45).until(\n",
        "                            EC.presence_of_element_located((By.CSS_SELECTOR, '#publicacao > div.col-lg-9.d-flex.flex-column > div > div > div > div.d-flex.flex-column-reverse.flex-sm-row.justify-content-sm-between.align-items-sm-center > div.d-flex.align-items-center.mb-3.mb-sm-0.d-print-none > download > div > div > a'))\n",
        "                        )\n",
        "                        download_href = download_button.get_attribute('href')\n",
        "\n",
        "                        # Fazer download do PDF\n",
        "                        pdf_response = requests.get(download_href)\n",
        "                        pdf_filename = f\"{text}.pdf\"\n",
        "                        with open(pdf_filename, 'wb') as pdf_file:\n",
        "                            pdf_file.write(pdf_response.content)\n",
        "\n",
        "                        # Extrair texto do PDF usando PyMuPDF\n",
        "                        pdf_text = ''\n",
        "                        with fitz.open(pdf_filename) as pdf_file:\n",
        "                            for page in pdf_file:\n",
        "                                page_text = page.get_text()\n",
        "                                pdf_text += page_text + '\\n'\n",
        "\n",
        "                        # Limpeza do texto\n",
        "                        pdf_text = pdf_text.replace('\\n', ' ')  # Remove quebras de linha\n",
        "                        pdf_text = re.sub(r'\\s+', ' ', pdf_text)  # Substitui múltiplos espaços por um único\n",
        "                        pdf_text = pdf_text.strip()  # Remove espaços no início e no fim\n",
        "\n",
        "                        # Print da primeira linha extraída\n",
        "                        first_line = pdf_text.split('.')[0]  # Considera a primeira frase\n",
        "                        #print(f'Primeira linha extraída: {first_line.strip()}')\n",
        "                        print(link_count)\n",
        "                    except (NoSuchElementException, TimeoutException):\n",
        "                        download_href = None\n",
        "                        pdf_text = None\n",
        "\n",
        "                    hrefs_and_texts.append((href, text, download_href, pdf_text))\n",
        "                    link_count += 1  # Incrementa o contador\n",
        "                    driver.back()\n",
        "                    WebDriverWait(driver, 15).until(EC.presence_of_element_located((By.CSS_SELECTOR, selector)))\n",
        "    except StaleElementReferenceException:\n",
        "        retrieve_links()\n",
        "\n",
        "# Iniciar a recuperação de links\n",
        "retrieve_links()\n",
        "\n",
        "# Fechar o driver\n",
        "driver.quit()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvLYZn946Hlr"
      },
      "source": [
        "Minhas stopwords e expressoes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "D7_zXjpX6HUz"
      },
      "outputs": [],
      "source": [
        "# Minhas stopwords\n",
        "my_stopwords = {\n",
        "    'January', 'February', 'March', 'April', 'May', 'June', 'July',\n",
        "    'August', 'September', 'October', 'November', 'December','january', 'february', 'march', 'april', 'may', 'june', 'July',\n",
        "    'august', 'september', 'october', 'november', 'december',\n",
        "    'minutes', 'bcb', 'th', 'copom', 'bcbgovbr', 'brasilia', 'pm','roberto'\n",
        "}\n",
        "\n",
        "# Array de expressões a serem removidas\n",
        "expressions_to_remove = [\n",
        "    'bcb.gov.br Minutes of the Meeting of the Monetary Policy Committee — Copom',\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Is8XaMx7-BIN"
      },
      "source": [
        "fazer o preprocessamento e criar o df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jRdPCx--8pb-",
        "outputId": "55a37807-6049-4c19-bc6e-75755846682a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  Link  \\\n",
            "0    https://www.bcb.gov.br/en/publications/copommi...   \n",
            "1    https://www.bcb.gov.br/en/publications/copommi...   \n",
            "2    https://www.bcb.gov.br/en/publications/copommi...   \n",
            "3    https://www.bcb.gov.br/en/publications/copommi...   \n",
            "4    https://www.bcb.gov.br/en/publications/copommi...   \n",
            "..                                                 ...   \n",
            "178  https://www.bcb.gov.br/en/publications/copommi...   \n",
            "179  https://www.bcb.gov.br/en/publications/copommi...   \n",
            "180  https://www.bcb.gov.br/en/publications/copommi...   \n",
            "181  https://www.bcb.gov.br/en/publications/copommi...   \n",
            "182  https://www.bcb.gov.br/en/publications/copommi...   \n",
            "\n",
            "                                     Texto  \\\n",
            "0    265th Meeting - September 17-18, 2024   \n",
            "1         264th Meeting - July 30-31, 2024   \n",
            "2         263rd Meeting - June 18-19, 2024   \n",
            "3            262nd Meeting - May 7-8, 2024   \n",
            "4        261st Meeting - March 19-20, 2024   \n",
            "..                                     ...   \n",
            "178       87th Copom minutes - August 2003   \n",
            "179         86th Copom minutes - July 2003   \n",
            "180         85th Copom minutes - June 2003   \n",
            "181          84th Copom minutes - May 2003   \n",
            "182        83rd Copom minutes - April 2003   \n",
            "\n",
            "                                      Link de Download  \\\n",
            "0    https://www.bcb.gov.br/content/copom/copomminu...   \n",
            "1    https://www.bcb.gov.br/content/copom/copomminu...   \n",
            "2    https://www.bcb.gov.br/content/copom/copomminu...   \n",
            "3    https://www.bcb.gov.br/content/copom/copomminu...   \n",
            "4    https://www.bcb.gov.br/content/copom/copomminu...   \n",
            "..                                                 ...   \n",
            "178  https://www.bcb.gov.br/content/copom/copomminu...   \n",
            "179  https://www.bcb.gov.br/content/copom/copomminu...   \n",
            "180  https://www.bcb.gov.br/content/copom/copomminu...   \n",
            "181  https://www.bcb.gov.br/content/copom/copomminu...   \n",
            "182  https://www.bcb.gov.br/content/copom/copomminu...   \n",
            "\n",
            "                                          Texto do PDF  \\\n",
            "0    1 bcb.gov.br Minutes of the Meeting of the Mon...   \n",
            "1    1 bcb.gov.br Minutes of the Meeting of the Mon...   \n",
            "2    1 bcb.gov.br Minutes of the Meeting of the Mon...   \n",
            "3    1 bcb.gov.br Minutes of the Meeting of the Mon...   \n",
            "4    1 bcb.gov.br Minutes of the Meeting of the Mon...   \n",
            "..                                                 ...   \n",
            "178  1 Minutes of the 87th Meeting of the Monetary ...   \n",
            "179  1 Minutes of the 86th Meeting of the Monetary ...   \n",
            "180  Minutes of the 85th Meeting of the Monetary Po...   \n",
            "181  Minutes of the 84th Meeting of the Monetary Po...   \n",
            "182  1 Minutes of the 83rd Meeting of the Monetary ...   \n",
            "\n",
            "                                      Texto Processado  \n",
            "0    meeting monetary policy committee meeting date...  \n",
            "1    meeting monetary policy committee july meeting...  \n",
            "2    meeting monetary policy committee rd rd meetin...  \n",
            "3    meeting monetary policy committee nd nd meetin...  \n",
            "4    meeting monetary policy committee st st meetin...  \n",
            "..                                                 ...  \n",
            "178  meeting monetary policy committee (copom) date...  \n",
            "179  meeting monetary policy committee (copom) date...  \n",
            "180  meeting monetary policy committee (copom) date...  \n",
            "181  meeting monetary policy committee (copom) date...  \n",
            "182  rd meeting monetary policy committee (copom) d...  \n",
            "\n",
            "[183 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "# Baixar as stopwords se ainda não tiver feito\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Criar um DataFrame com os links e textos extraídos\n",
        "df = pd.DataFrame(hrefs_and_texts, columns=['Link', 'Texto', 'Link de Download', 'Texto do PDF'])\n",
        "\n",
        "# Carregar stopwords em inglês\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stop_words.update(my_stopwords)\n",
        "\n",
        "# Função para preprocessar o texto\n",
        "def preprocess_text(text):\n",
        "    if text:\n",
        "        # Remover números, pontuação e caracteres especiais\n",
        "        text = re.sub(r'[0-9]+', '', text)  # Remove números\n",
        "        # Remover pontuação, exceto parênteses\n",
        "        text = re.sub(r'[^\\w\\s()]+', '', text)  # Mantém letras, números, espaços e parênteses\n",
        "        text = re.sub(r'\\s+', ' ', text)  # Substituir múltiplos espaços por um único espaço\n",
        "        text = text.strip().lower()  # Retorna texto em minúsculas\n",
        "\n",
        "        # Remover expressões específicas\n",
        "        for expr in expressions_to_remove:\n",
        "            text = text.replace(expr, '')\n",
        "\n",
        "        # Remover stopwords\n",
        "        text = ' '.join([word for word in text.split() if word not in stop_words])\n",
        "        return text\n",
        "    return ''\n",
        "\n",
        "# Criar a nova coluna 'Texto Processado'\n",
        "df['Texto Processado'] = df['Texto do PDF'].apply(preprocess_text)\n",
        "\n",
        "# Imprimir o DataFrame\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "collapsed": true,
        "id": "pd-A0QrjI-xe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeffbe51-2fb2-4beb-e999-f38447b72c90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  Link  \\\n",
            "0    https://www.bcb.gov.br/en/publications/copommi...   \n",
            "1    https://www.bcb.gov.br/en/publications/copommi...   \n",
            "2    https://www.bcb.gov.br/en/publications/copommi...   \n",
            "3    https://www.bcb.gov.br/en/publications/copommi...   \n",
            "4    https://www.bcb.gov.br/en/publications/copommi...   \n",
            "..                                                 ...   \n",
            "178  https://www.bcb.gov.br/en/publications/copommi...   \n",
            "179  https://www.bcb.gov.br/en/publications/copommi...   \n",
            "180  https://www.bcb.gov.br/en/publications/copommi...   \n",
            "181  https://www.bcb.gov.br/en/publications/copommi...   \n",
            "182  https://www.bcb.gov.br/en/publications/copommi...   \n",
            "\n",
            "                                     Texto  \\\n",
            "0    265th Meeting - September 17-18, 2024   \n",
            "1         264th Meeting - July 30-31, 2024   \n",
            "2         263rd Meeting - June 18-19, 2024   \n",
            "3            262nd Meeting - May 7-8, 2024   \n",
            "4        261st Meeting - March 19-20, 2024   \n",
            "..                                     ...   \n",
            "178       87th Copom minutes - August 2003   \n",
            "179         86th Copom minutes - July 2003   \n",
            "180         85th Copom minutes - June 2003   \n",
            "181          84th Copom minutes - May 2003   \n",
            "182        83rd Copom minutes - April 2003   \n",
            "\n",
            "                                      Link de Download  \\\n",
            "0    https://www.bcb.gov.br/content/copom/copomminu...   \n",
            "1    https://www.bcb.gov.br/content/copom/copomminu...   \n",
            "2    https://www.bcb.gov.br/content/copom/copomminu...   \n",
            "3    https://www.bcb.gov.br/content/copom/copomminu...   \n",
            "4    https://www.bcb.gov.br/content/copom/copomminu...   \n",
            "..                                                 ...   \n",
            "178  https://www.bcb.gov.br/content/copom/copomminu...   \n",
            "179  https://www.bcb.gov.br/content/copom/copomminu...   \n",
            "180  https://www.bcb.gov.br/content/copom/copomminu...   \n",
            "181  https://www.bcb.gov.br/content/copom/copomminu...   \n",
            "182  https://www.bcb.gov.br/content/copom/copomminu...   \n",
            "\n",
            "                                          Texto do PDF  \\\n",
            "0    1 bcb.gov.br Minutes of the Meeting of the Mon...   \n",
            "1    1 bcb.gov.br Minutes of the Meeting of the Mon...   \n",
            "2    1 bcb.gov.br Minutes of the Meeting of the Mon...   \n",
            "3    1 bcb.gov.br Minutes of the Meeting of the Mon...   \n",
            "4    1 bcb.gov.br Minutes of the Meeting of the Mon...   \n",
            "..                                                 ...   \n",
            "178  1 Minutes of the 87th Meeting of the Monetary ...   \n",
            "179  1 Minutes of the 86th Meeting of the Monetary ...   \n",
            "180  Minutes of the 85th Meeting of the Monetary Po...   \n",
            "181  Minutes of the 84th Meeting of the Monetary Po...   \n",
            "182  1 Minutes of the 83rd Meeting of the Monetary ...   \n",
            "\n",
            "                                      Texto Processado  Ano_Mes  \n",
            "0    meeting monetary policy committee meeting date...  2024-09  \n",
            "1    meeting monetary policy committee july meeting...  2024-07  \n",
            "2    meeting monetary policy committee rd rd meetin...  2024-06  \n",
            "3    meeting monetary policy committee nd nd meetin...  2024-05  \n",
            "4    meeting monetary policy committee st st meetin...  2024-03  \n",
            "..                                                 ...      ...  \n",
            "178  meeting monetary policy committee (copom) date...  2003-08  \n",
            "179  meeting monetary policy committee (copom) date...  2003-07  \n",
            "180  meeting monetary policy committee (copom) date...  2003-06  \n",
            "181  meeting monetary policy committee (copom) date...  2003-05  \n",
            "182  rd meeting monetary policy committee (copom) d...  2003-04  \n",
            "\n",
            "[183 rows x 6 columns]\n"
          ]
        }
      ],
      "source": [
        "# Função para extrair ano e mês\n",
        "def extract_year_month(text):\n",
        "    # Caso 1: Formato com dia e mês\n",
        "    match_full = re.search(r'(\\w+)\\s+\\d{1,2}[- ]\\d{1,2},\\s*(\\d{4})', text)\n",
        "    # Caso 2: Formato apenas com mês e ano\n",
        "    match_month_year = re.search(r'(\\w+)\\s+(\\d{4})', text)\n",
        "    # Caso 3: Formato com intervalo de datas\n",
        "    match_interval = re.search(r'(\\w+)\\s+\\d{1,2}\\s*-\\s*(\\w+)\\s+\\d{1,2},\\s*(\\d{4})', text)\n",
        "\n",
        "    if match_full:\n",
        "        month_str = match_full.group(1)\n",
        "        year = match_full.group(2)\n",
        "    elif match_month_year:\n",
        "        month_str = match_month_year.group(1)\n",
        "        year = match_month_year.group(2)\n",
        "    elif match_interval:\n",
        "        month_str = match_interval.group(2)  # Captura o mês da última data\n",
        "        year = match_interval.group(3)\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "    # Converter mês para número\n",
        "    month_num = pd.to_datetime(month_str, format='%B').month\n",
        "    return f\"{year}-{month_num:02d}\"  # Formatar como YYYY-MM\n",
        "\n",
        "# Criar nova coluna com ano e mês\n",
        "df['Ano_Mes'] = df['Texto'].apply(extract_year_month)\n",
        "\n",
        "# Exibir o DataFrame resultante\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "nFcN5ZtWbdxE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b17daaf7-cc6e-4b24-9b0e-eadbf707683f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                      Texto Processado\n",
            "0    a) update economic outlook copoms scenario glo...\n",
            "1    a) update economic outlook copoms scenario glo...\n",
            "2    a) update economic outlook copoms scenario glo...\n",
            "3    a) update economic outlook copoms scenario glo...\n",
            "4    a) update economic outlook copoms scenario glo...\n",
            "..                                                 ...\n",
            "178  recent evolution inflation inflation rates jul...\n",
            "179  recent evolution inflation inflation continued...\n",
            "180  recent evolution inflation measures inflation ...\n",
            "181  recent evolution inflation measures inflation ...\n",
            "182  recent evolution inflation consumer price infl...\n",
            "\n",
            "[183 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "# Definir as expressões que você deseja encontrar\n",
        "expressions = [\n",
        "    r'(?i)(A\\)\\s*update (?:e conomic|economic) outlook (?:c opoms|copoms) (?:reference|baseline|)\\s*scenario)(.*)',\n",
        "    r'(?i)(Recent Economic Developments)(.*)',\n",
        "    r'(?i)(Recent Evolution Inflation)(.*)',\n",
        "]\n",
        "\n",
        "# Função para extrair texto a partir de várias expressões\n",
        "def extract_from_expressions(text):\n",
        "    for pattern in expressions:\n",
        "        match = re.search(pattern, text)\n",
        "        if match:\n",
        "            # Retorna o texto a partir da expressão encontrada até o final\n",
        "            return text[match.start():]  # A partir do início da expressão até o final do texto\n",
        "    return text  # Retorna todo o texto se nenhuma expressão for encontrada\n",
        "\n",
        "df['Texto Processado'] = df['Texto Processado'].apply(extract_from_expressions)\n",
        "\n",
        "\n",
        "# Definir os títulos das seções, permitindo variações com ou sem espaço\n",
        "section_titles = [\n",
        "    r'(?i)A\\)\\s*update (?:e conomic|economic) outlook (?:c opoms|copoms) (?:reference|baseline|)\\s*scenario.*?(?=B\\)\\s*risks around|B\\)\\s*scenarios risk analysis|$)',\n",
        "    r'(?i)(B\\)\\s*risks around|B\\)\\s*scenarios risk analysis).*?(?=C\\)\\s*discussion conduct monetary policy|$)',\n",
        "    r'(?i)C\\)\\s*discussion conduct monetary policy.*?(?=D\\)\\s*monetary policy decision|$)',\n",
        "    r'(?i)D\\)\\s*monetary policy decision.*?(?=Footnotes|$)',\n",
        "    r'(?i)Footnotes.*'  # Captura tudo até o final do texto\n",
        "]\n",
        "\n",
        "\n",
        "# Criar variáveis para cada seção no DataFrame\n",
        "for title in section_titles:\n",
        "    # Usar str.extract para capturar as seções\n",
        "    section_name = re.search(r'A|B|C|D|Footnotes', title).group(0)  # Captura A, B, C, D ou Footnotes\n",
        "    df[section_name] = df['Texto Processado'].str.extract(f'({title})')[0]\n",
        "\n",
        "print (df[['Texto Processado']])\n",
        "# Exibir o DataFrame resultante\n",
        "#print(df[['A', 'B', 'C', 'D', 'Footnotes']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezMA27xpdUbv"
      },
      "source": [
        "Carregar a base dos pibs trimestrais"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "jDDlDELndUq1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9c62fe82-3510-4025-8bc1-9036c4c6bd6b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-41988e33-1303-475f-a203-821b52292103\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-41988e33-1303-475f-a203-821b52292103\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving pib_trimestral.csv to pib_trimestral.csv\n",
            "DataFrame após a leitura:\n",
            "   1º trimestre 1996  2º trimestre 1996  3º trimestre 1996  4º trimestre 1996  \\\n",
            "0                2.5                2.1                2.3                2.2   \n",
            "\n",
            "   1º trimestre 1997  2º trimestre 1997  3º trimestre 1997  4º trimestre 1997  \\\n",
            "0                3.2                4.0                3.0                3.4   \n",
            "\n",
            "   1º trimestre 1998  2º trimestre 1998  ...  1º trimestre 2022  \\\n",
            "0                2.8                2.0  ...                4.7   \n",
            "\n",
            "   2º trimestre 2022  3º trimestre 2022  4º trimestre 2022  1º trimestre 2023  \\\n",
            "0                2.7                2.7                3.0                3.7   \n",
            "\n",
            "   2º trimestre 2023  3º trimestre 2023  4º trimestre 2023  1º trimestre 2024  \\\n",
            "0                3.7                3.1                2.9                2.5   \n",
            "\n",
            "   2º trimestre 2024  \n",
            "0                2.5  \n",
            "\n",
            "[1 rows x 114 columns]\n",
            "DataFrame derretido:\n",
            "           Trimestre  Valor\n",
            "0  1º trimestre 1996    2.5\n",
            "1  2º trimestre 1996    2.1\n",
            "2  3º trimestre 1996    2.3\n",
            "3  4º trimestre 1996    2.2\n",
            "4  1º trimestre 1997    3.2\n",
            "DataFrame com o mapeamento:\n",
            "            Trimestre  Ano_Mes\n",
            "0   1º trimestre 1996  1996-03\n",
            "1   2º trimestre 1996  1996-06\n",
            "2   3º trimestre 1996  1996-09\n",
            "3   4º trimestre 1996  1996-12\n",
            "4   1º trimestre 1997  1997-03\n",
            "5   2º trimestre 1997  1997-06\n",
            "6   3º trimestre 1997  1997-09\n",
            "7   4º trimestre 1997  1997-12\n",
            "8   1º trimestre 1998  1998-03\n",
            "9   2º trimestre 1998  1998-06\n",
            "10  3º trimestre 1998  1998-09\n",
            "11  4º trimestre 1998  1998-12\n",
            "12  1º trimestre 1999  1999-03\n",
            "13  2º trimestre 1999  1999-06\n",
            "14  3º trimestre 1999  1999-09\n",
            "15  4º trimestre 1999  1999-12\n",
            "16  1º trimestre 2000  2000-03\n",
            "17  2º trimestre 2000  2000-06\n",
            "18  3º trimestre 2000  2000-09\n",
            "19  4º trimestre 2000  2000-12\n",
            "Número de valores ausentes em 'Ano_Mes': 0\n",
            "1º trimestre 1996: ['1996-03']\n",
            "2º trimestre 1996: ['1996-06']\n",
            "3º trimestre 1996: ['1996-09']\n",
            "4º trimestre 1996: ['1996-12']\n",
            "1º trimestre 1997: ['1997-03']\n",
            "2º trimestre 1997: ['1997-06']\n",
            "3º trimestre 1997: ['1997-09']\n",
            "4º trimestre 1997: ['1997-12']\n",
            "1º trimestre 1998: ['1998-03']\n",
            "2º trimestre 1998: ['1998-06']\n",
            "3º trimestre 1998: ['1998-09']\n",
            "4º trimestre 1998: ['1998-12']\n",
            "1º trimestre 1999: ['1999-03']\n",
            "2º trimestre 1999: ['1999-06']\n",
            "3º trimestre 1999: ['1999-09']\n",
            "4º trimestre 1999: ['1999-12']\n",
            "1º trimestre 2000: ['2000-03']\n",
            "2º trimestre 2000: ['2000-06']\n",
            "3º trimestre 2000: ['2000-09']\n",
            "4º trimestre 2000: ['2000-12']\n",
            "1º trimestre 2001: ['2001-03']\n",
            "2º trimestre 2001: ['2001-06']\n",
            "3º trimestre 2001: ['2001-09']\n",
            "4º trimestre 2001: ['2001-12']\n",
            "1º trimestre 2002: ['2002-03']\n",
            "2º trimestre 2002: ['2002-06']\n",
            "3º trimestre 2002: ['2002-09']\n",
            "4º trimestre 2002: ['2002-12']\n",
            "1º trimestre 2003: ['2003-03']\n",
            "2º trimestre 2003: ['2003-06']\n",
            "3º trimestre 2003: ['2003-09']\n",
            "4º trimestre 2003: ['2003-12']\n",
            "1º trimestre 2004: ['2004-03']\n",
            "2º trimestre 2004: ['2004-06']\n",
            "3º trimestre 2004: ['2004-09']\n",
            "4º trimestre 2004: ['2004-12']\n",
            "1º trimestre 2005: ['2005-03']\n",
            "2º trimestre 2005: ['2005-06']\n",
            "3º trimestre 2005: ['2005-09']\n",
            "4º trimestre 2005: ['2005-12']\n",
            "1º trimestre 2006: ['2006-03']\n",
            "2º trimestre 2006: ['2006-06']\n",
            "3º trimestre 2006: ['2006-09']\n",
            "4º trimestre 2006: ['2006-12']\n",
            "1º trimestre 2007: ['2007-03']\n",
            "2º trimestre 2007: ['2007-06']\n",
            "3º trimestre 2007: ['2007-09']\n",
            "4º trimestre 2007: ['2007-12']\n",
            "1º trimestre 2008: ['2008-03']\n",
            "2º trimestre 2008: ['2008-06']\n",
            "3º trimestre 2008: ['2008-09']\n",
            "4º trimestre 2008: ['2008-12']\n",
            "1º trimestre 2009: ['2009-03']\n",
            "2º trimestre 2009: ['2009-06']\n",
            "3º trimestre 2009: ['2009-09']\n",
            "4º trimestre 2009: ['2009-12']\n",
            "1º trimestre 2010: ['2010-03']\n",
            "2º trimestre 2010: ['2010-06']\n",
            "3º trimestre 2010: ['2010-09']\n",
            "4º trimestre 2010: ['2010-12']\n",
            "1º trimestre 2011: ['2011-03']\n",
            "2º trimestre 2011: ['2011-06']\n",
            "3º trimestre 2011: ['2011-09']\n",
            "4º trimestre 2011: ['2011-12']\n",
            "1º trimestre 2012: ['2012-03']\n",
            "2º trimestre 2012: ['2012-06']\n",
            "3º trimestre 2012: ['2012-09']\n",
            "4º trimestre 2012: ['2012-12']\n",
            "1º trimestre 2013: ['2013-03']\n",
            "2º trimestre 2013: ['2013-06']\n",
            "3º trimestre 2013: ['2013-09']\n",
            "4º trimestre 2013: ['2013-12']\n",
            "1º trimestre 2014: ['2014-03']\n",
            "2º trimestre 2014: ['2014-06']\n",
            "3º trimestre 2014: ['2014-09']\n",
            "4º trimestre 2014: ['2014-12']\n",
            "1º trimestre 2015: ['2015-03']\n",
            "2º trimestre 2015: ['2015-06']\n",
            "3º trimestre 2015: ['2015-09']\n",
            "4º trimestre 2015: ['2015-12']\n",
            "1º trimestre 2016: ['2016-03']\n",
            "2º trimestre 2016: ['2016-06']\n",
            "3º trimestre 2016: ['2016-09']\n",
            "4º trimestre 2016: ['2016-12']\n",
            "1º trimestre 2017: ['2017-03']\n",
            "2º trimestre 2017: ['2017-06']\n",
            "3º trimestre 2017: ['2017-09']\n",
            "4º trimestre 2017: ['2017-12']\n",
            "1º trimestre 2018: ['2018-03']\n",
            "2º trimestre 2018: ['2018-06']\n",
            "3º trimestre 2018: ['2018-09']\n",
            "4º trimestre 2018: ['2018-12']\n",
            "1º trimestre 2019: ['2019-03']\n",
            "2º trimestre 2019: ['2019-06']\n",
            "3º trimestre 2019: ['2019-09']\n",
            "4º trimestre 2019: ['2019-12']\n",
            "1º trimestre 2020: ['2020-03']\n",
            "2º trimestre 2020: ['2020-06']\n",
            "3º trimestre 2020: ['2020-09']\n",
            "4º trimestre 2020: ['2020-12']\n",
            "1º trimestre 2021: ['2021-03']\n",
            "2º trimestre 2021: ['2021-06']\n",
            "3º trimestre 2021: ['2021-09']\n",
            "4º trimestre 2021: ['2021-12']\n",
            "1º trimestre 2022: ['2022-03']\n",
            "2º trimestre 2022: ['2022-06']\n",
            "3º trimestre 2022: ['2022-09']\n",
            "4º trimestre 2022: ['2022-12']\n",
            "1º trimestre 2023: ['2023-03']\n",
            "2º trimestre 2023: ['2023-06']\n",
            "3º trimestre 2023: ['2023-09']\n",
            "4º trimestre 2023: ['2023-12']\n",
            "1º trimestre 2024: ['2024-03']\n",
            "2º trimestre 2024: ['2024-06']\n",
            "Trimestres únicos:\n",
            "['1º trimestre 1996' '2º trimestre 1996' '3º trimestre 1996'\n",
            " '4º trimestre 1996' '1º trimestre 1997' '2º trimestre 1997'\n",
            " '3º trimestre 1997' '4º trimestre 1997' '1º trimestre 1998'\n",
            " '2º trimestre 1998' '3º trimestre 1998' '4º trimestre 1998'\n",
            " '1º trimestre 1999' '2º trimestre 1999' '3º trimestre 1999'\n",
            " '4º trimestre 1999' '1º trimestre 2000' '2º trimestre 2000'\n",
            " '3º trimestre 2000' '4º trimestre 2000' '1º trimestre 2001'\n",
            " '2º trimestre 2001' '3º trimestre 2001' '4º trimestre 2001'\n",
            " '1º trimestre 2002' '2º trimestre 2002' '3º trimestre 2002'\n",
            " '4º trimestre 2002' '1º trimestre 2003' '2º trimestre 2003'\n",
            " '3º trimestre 2003' '4º trimestre 2003' '1º trimestre 2004'\n",
            " '2º trimestre 2004' '3º trimestre 2004' '4º trimestre 2004'\n",
            " '1º trimestre 2005' '2º trimestre 2005' '3º trimestre 2005'\n",
            " '4º trimestre 2005' '1º trimestre 2006' '2º trimestre 2006'\n",
            " '3º trimestre 2006' '4º trimestre 2006' '1º trimestre 2007'\n",
            " '2º trimestre 2007' '3º trimestre 2007' '4º trimestre 2007'\n",
            " '1º trimestre 2008' '2º trimestre 2008' '3º trimestre 2008'\n",
            " '4º trimestre 2008' '1º trimestre 2009' '2º trimestre 2009'\n",
            " '3º trimestre 2009' '4º trimestre 2009' '1º trimestre 2010'\n",
            " '2º trimestre 2010' '3º trimestre 2010' '4º trimestre 2010'\n",
            " '1º trimestre 2011' '2º trimestre 2011' '3º trimestre 2011'\n",
            " '4º trimestre 2011' '1º trimestre 2012' '2º trimestre 2012'\n",
            " '3º trimestre 2012' '4º trimestre 2012' '1º trimestre 2013'\n",
            " '2º trimestre 2013' '3º trimestre 2013' '4º trimestre 2013'\n",
            " '1º trimestre 2014' '2º trimestre 2014' '3º trimestre 2014'\n",
            " '4º trimestre 2014' '1º trimestre 2015' '2º trimestre 2015'\n",
            " '3º trimestre 2015' '4º trimestre 2015' '1º trimestre 2016'\n",
            " '2º trimestre 2016' '3º trimestre 2016' '4º trimestre 2016'\n",
            " '1º trimestre 2017' '2º trimestre 2017' '3º trimestre 2017'\n",
            " '4º trimestre 2017' '1º trimestre 2018' '2º trimestre 2018'\n",
            " '3º trimestre 2018' '4º trimestre 2018' '1º trimestre 2019'\n",
            " '2º trimestre 2019' '3º trimestre 2019' '4º trimestre 2019'\n",
            " '1º trimestre 2020' '2º trimestre 2020' '3º trimestre 2020'\n",
            " '4º trimestre 2020' '1º trimestre 2021' '2º trimestre 2021'\n",
            " '3º trimestre 2021' '4º trimestre 2021' '1º trimestre 2022'\n",
            " '2º trimestre 2022' '3º trimestre 2022' '4º trimestre 2022'\n",
            " '1º trimestre 2023' '2º trimestre 2023' '3º trimestre 2023'\n",
            " '4º trimestre 2023' '1º trimestre 2024' '2º trimestre 2024']\n",
            "     Ano_Mes  Valor\n",
            "0    1996-03    2.5\n",
            "1    1996-06    2.1\n",
            "2    1996-09    2.3\n",
            "3    1996-12    2.2\n",
            "4    1997-03    3.2\n",
            "..       ...    ...\n",
            "109  2023-06    3.7\n",
            "110  2023-09    3.1\n",
            "111  2023-12    2.9\n",
            "112  2024-03    2.5\n",
            "113  2024-06    2.5\n",
            "\n",
            "[114 rows x 2 columns]\n",
            "                                                 Link  \\\n",
            "29  https://www.bcb.gov.br/en/publications/copommi...   \n",
            "30  https://www.bcb.gov.br/en/publications/copommi...   \n",
            "31  https://www.bcb.gov.br/en/publications/copommi...   \n",
            "32  https://www.bcb.gov.br/en/publications/copommi...   \n",
            "33  https://www.bcb.gov.br/en/publications/copommi...   \n",
            "\n",
            "                               Texto  \\\n",
            "29   83rd Copom minutes - April 2003   \n",
            "30     84th Copom minutes - May 2003   \n",
            "31    85th Copom minutes - June 2003   \n",
            "32    86th Copom minutes - July 2003   \n",
            "33  87th Copom minutes - August 2003   \n",
            "\n",
            "                                     Link de Download  \\\n",
            "29  https://www.bcb.gov.br/content/copom/copomminu...   \n",
            "30  https://www.bcb.gov.br/content/copom/copomminu...   \n",
            "31  https://www.bcb.gov.br/content/copom/copomminu...   \n",
            "32  https://www.bcb.gov.br/content/copom/copomminu...   \n",
            "33  https://www.bcb.gov.br/content/copom/copomminu...   \n",
            "\n",
            "                                         Texto do PDF  \\\n",
            "29  1 Minutes of the 83rd Meeting of the Monetary ...   \n",
            "30  Minutes of the 84th Meeting of the Monetary Po...   \n",
            "31  Minutes of the 85th Meeting of the Monetary Po...   \n",
            "32  1 Minutes of the 86th Meeting of the Monetary ...   \n",
            "33  1 Minutes of the 87th Meeting of the Monetary ...   \n",
            "\n",
            "                                     Texto Processado  Ano_Mes    A    B    C  \\\n",
            "29  recent evolution inflation consumer price infl...  2003-04  NaN  NaN  NaN   \n",
            "30  recent evolution inflation measures inflation ...  2003-05  NaN  NaN  NaN   \n",
            "31  recent evolution inflation measures inflation ...  2003-06  NaN  NaN  NaN   \n",
            "32  recent evolution inflation inflation continued...  2003-07  NaN  NaN  NaN   \n",
            "33  recent evolution inflation inflation rates jul...  2003-08  NaN  NaN  NaN   \n",
            "\n",
            "      D Footnotes  Valor  \n",
            "29  NaN       NaN    NaN  \n",
            "30  NaN       NaN    NaN  \n",
            "31  NaN       NaN    3.2  \n",
            "32  NaN       NaN    NaN  \n",
            "33  NaN       NaN    NaN  \n"
          ]
        }
      ],
      "source": [
        "# https://www.ibge.gov.br/estatisticas/economicas/contas-nacionais/9300-contas-nacionais-trimestrais.html?=&t=series-historicas&utm_source=landing&utm_medium=explica&utm_campaign=pib#evolucao-taxa\n",
        "\n",
        "# Fazendo upload do arquivo CSV\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Carregar o arquivo CSV usando o delimitador correto\n",
        "df_trimestres = pd.read_csv('pib_trimestral.csv', delimiter=';', header=1)  # O cabeçalho correto\n",
        "\n",
        "# Excluir a primeira coluna se necessário (baseado no que você descreveu)\n",
        "df_trimestres = df_trimestres.iloc[:1, 1:]  # Remove a primeira coluna\n",
        "\n",
        "\n",
        "# Verifique o DataFrame após as alterações\n",
        "print(\"DataFrame após a leitura:\")\n",
        "print(df_trimestres.head())\n",
        "\n",
        "# Agora, precisamos reorganizar os dados\n",
        "# Vamos usar melt para transformar os dados\n",
        "df_trimestres_melted = df_trimestres.melt(var_name='Trimestre', value_name='Valor')\n",
        "\n",
        "# Verifique o DataFrame derretido\n",
        "print(\"DataFrame derretido:\")\n",
        "print(df_trimestres_melted.head())\n",
        "\n",
        "# Função para gerar mapeamento de trimestres\n",
        "def gerar_mapeamento_trimestres(inicio_ano, fim_ano):\n",
        "    mapeamento = {}\n",
        "    for ano in range(inicio_ano, fim_ano + 1):\n",
        "        for trimestre in range(1, 5):\n",
        "            mes = trimestre * 3  # 1: Março, 2: Junho, 3: Setembro, 4: Dezembro\n",
        "            ano_mes = f\"{ano}-{mes:02d}\"\n",
        "            mapeamento[f\"{trimestre}º trimestre {ano}\"] = ano_mes\n",
        "    return mapeamento\n",
        "\n",
        "# Gerar mapeamento de 1996 a 2024\n",
        "mapeamento_trimestre = gerar_mapeamento_trimestres(1996, 2024)\n",
        "df_trimestres_melted['Ano_Mes'] = df_trimestres_melted['Trimestre'].map(mapeamento_trimestre)\n",
        "\n",
        "print(\"DataFrame com o mapeamento:\")\n",
        "print(df_trimestres_melted[['Trimestre', 'Ano_Mes']].head(20))  # Exibir as primeiras 20 linhas\n",
        "\n",
        "# Verificar se há valores ausentes na coluna Ano_Mes\n",
        "valores_ausentes = df_trimestres_melted['Ano_Mes'].isna().sum()\n",
        "print(f\"Número de valores ausentes em 'Ano_Mes': {valores_ausentes}\")\n",
        "\n",
        "# Exibir trimestres e seus respectivos Ano_Mes\n",
        "for trimestre in df_trimestres_melted['Trimestre'].unique():\n",
        "    print(f\"{trimestre}: {df_trimestres_melted[df_trimestres_melted['Trimestre'] == trimestre]['Ano_Mes'].values}\")\n",
        "\n",
        "\n",
        "# Verifique o resultado do mapeamento\n",
        "print(\"Trimestres únicos:\")\n",
        "print(df_trimestres_melted['Trimestre'].unique())\n",
        "print(df_trimestres_melted[['Ano_Mes', 'Valor']])\n",
        "\n",
        "\n",
        "# Agora, mescle os dois dataframes (supondo que o df original esteja carregado em df)\n",
        "df_final = pd.merge(df, df_trimestres_melted[['Ano_Mes', 'Valor']], on='Ano_Mes', how='outer')\n",
        "#df_final = df_final.dropna(subset=['Texto Processado'])\n",
        "\n",
        "#drop de 2003-03 para tras\n",
        "# Filtra para manter apenas os registros a partir de 2003-03\n",
        "df_final = df_final[df_final['Ano_Mes'] >= '2003-04']\n",
        "\n",
        "# Verifique o resultado final\n",
        "print(df_final.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3elGo5vXpTg"
      },
      "source": [
        "Treinando o modelo Word2vec. Utilizando o Texto Processado como corpus (A PARTIR DAQUI COM O XLSX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "M4ONo7dRXya2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "985179d9-9215-495f-f819-f014013669ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treinando Word2Vec...\n"
          ]
        }
      ],
      "source": [
        "# Carregar o CSV (Para nao precisar rodar tudo novamente)\n",
        "import requests\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "from gensim.models import KeyedVectors, Word2Vec\n",
        "import gensim\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from statsmodels.tsa.ar_model import AutoReg\n",
        "\n",
        "#-------------------------------------------------------------\n",
        "#excel\n",
        "\n",
        "# Faça o upload do arquivo\n",
        "#uploaded = files.upload()\n",
        "\n",
        "# Carregando o arquivo Excel corretamente\n",
        "#df_final = pd.read_excel('corpus.xlsx')  # Corrigido para corpus.xlsx\n",
        "\n",
        "# Extraindo a quarta coluna como corpus\n",
        "#corpus = df.iloc[:, 4].tolist()  # Altere o índice se necessário\n",
        "\n",
        "#---------------------------------------------------------------------\n",
        "#DF\n",
        "# Extraindo a quarta coluna como corpus\n",
        "corpus = df_final['Texto Processado'].tolist()  # Altere o índice se necessário\n",
        "\n",
        "\n",
        "#---------------------------------------------------------------------\n",
        "corpus = [text for text in corpus if isinstance(text, str) and text.strip() != \"\"]\n",
        "\n",
        "# Pré-processamento do texto (divisão em palavras)\n",
        "# Aqui estamos usando um simples split, mas você pode querer fazer mais pré-processamento\n",
        "corpus_tokenized = [text.split() for text in corpus]\n",
        "\n",
        "# Word2Vec (cbow)\n",
        "print(\"Treinando Word2Vec...\")\n",
        "word2vec_model = gensim.models.Word2Vec(corpus_tokenized, vector_size=100, window=5, min_count=1, workers=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siTEycAE9yWV"
      },
      "source": [
        "Criando o vetor medio dos vetores medios das atas referente ao trimestre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "0tIViDeC9y6Z"
      },
      "outputs": [],
      "source": [
        "# Função para obter o vetor médio\n",
        "def get_average_vector(text):\n",
        "    if isinstance(text, str):  # Verifica se o texto é uma string\n",
        "        words = text.split()\n",
        "        word_vectors = [word2vec_model.wv[word] for word in words if word in word2vec_model.wv]\n",
        "        if word_vectors:\n",
        "            return np.mean(word_vectors, axis=0)\n",
        "    return np.zeros(word2vec_model.vector_size)  # Retorna vetor zero se não houver palavras válidas ou se o texto não for string\n",
        "\n",
        "# Criar a nova coluna 'Texto Processado'\n",
        "df_final['Vetor Médio'] = df_final['Texto Processado'].apply(get_average_vector)\n",
        "\n",
        "# Inicializa uma lista para os vetores médios do trimestre\n",
        "vetores_medio_trimeste = []\n",
        "previous_vectors = []  # Lista para acumular vetores das linhas com valor missing\n",
        "\n",
        "# Para cada linha no DataFrame\n",
        "for i in range(len(df_final)):\n",
        "    current_vector = df_final['Vetor Médio'].iloc[i]\n",
        "\n",
        "    # Se o valor não for missing\n",
        "    if not np.isnan(df_final['Valor'].iloc[i]):\n",
        "        has_zero_vector = np.array_equal(current_vector, np.zeros(word2vec_model.vector_size))\n",
        "\n",
        "        # Se houver vetores acumulados, calcula a média\n",
        "        if previous_vectors:\n",
        "            # Filtra apenas vetores válidos para o cálculo da média\n",
        "            valid_vectors = [v for v in previous_vectors if not np.array_equal(v, np.zeros(word2vec_model.vector_size))]\n",
        "            if valid_vectors:\n",
        "                # Calcula a média entre o vetor acumulado e o vetor atual\n",
        "                vetor_medio_final = np.mean([np.mean(valid_vectors, axis=0), current_vector], axis=0)\n",
        "                if has_zero_vector:\n",
        "                    vetor_medio_final *= 2  # Multiplica por 2 se houver pelo menos um vetor inválido\n",
        "                vetores_medio_trimeste.append(vetor_medio_final)\n",
        "            else:\n",
        "                vetores_medio_trimeste.append(current_vector * 2)  # Se não houver vetores válidos, usa o vetor atual\n",
        "        else:\n",
        "            vetores_medio_trimeste.append(current_vector)\n",
        "\n",
        "        # Limpa a lista acumulada para o próximo conjunto\n",
        "        previous_vectors = []\n",
        "    else:\n",
        "        # Se o valor for missing, acumula o vetor médio\n",
        "        if not np.array_equal(current_vector, np.zeros(word2vec_model.vector_size)):\n",
        "            previous_vectors.append(current_vector)\n",
        "        vetores_medio_trimeste.append(None)  # Adiciona None para os missing\n",
        "\n",
        "# Adiciona a nova coluna ao DataFrame\n",
        "df_final['vetor_medio_trimestre'] = vetores_medio_trimeste\n",
        "\n",
        "# Verifica o resultado\n",
        "#print(df_final[['Texto Processado', 'Valor', 'Vetor Médio', 'vetor_medio_trimestre']].head(20))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GX_7-qp6DXY6"
      },
      "source": [
        "Previsao"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JRltligzDZy5",
        "outputId": "7f5b5805-29f5-46e2-f718-8c726a260bd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31     [-0.36054844, 0.10639507, 0.28305176, 0.337040...\n",
            "34     [-0.324018, 0.118333995, 0.3041522, 0.3236421,...\n",
            "37     [-0.27688137, 0.12061549, 0.27072445, 0.297198...\n",
            "40     [-0.34773308, 0.14291504, 0.27324387, 0.356159...\n",
            "43     [-0.3437688, 0.17840719, 0.3018998, 0.33651412...\n",
            "                             ...                        \n",
            "218    [-0.59499896, 0.21484083, -0.01446094, 0.18904...\n",
            "220    [-0.58919513, 0.2061033, -0.042458683, 0.21070...\n",
            "222    [-0.6102571, 0.24269715, -0.025317485, 0.15900...\n",
            "224    [-0.64068836, 0.22806332, -0.05927429, 0.15277...\n",
            "226    [-0.60022545, 0.2745545, -0.021278743, 0.19165...\n",
            "Name: vetor_medio_trimestre, Length: 85, dtype: object\n",
            "                            AutoReg Model Results                             \n",
            "==============================================================================\n",
            "Dep. Variable:                      y   No. Observations:                   85\n",
            "Model:                     AutoReg(2)   Log Likelihood                -106.716\n",
            "Method:               Conditional MLE   S.D. of innovations              0.875\n",
            "Date:                Thu, 10 Oct 2024   AIC                            221.433\n",
            "Time:                        19:28:51   BIC                            231.108\n",
            "Sample:                             2   HQIC                           225.320\n",
            "                                   85                                         \n",
            "==============================================================================\n",
            "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const          0.3242      0.123      2.626      0.009       0.082       0.566\n",
            "y.L1           1.5086      0.083     18.172      0.000       1.346       1.671\n",
            "y.L2          -0.6492      0.083     -7.825      0.000      -0.812      -0.487\n",
            "                                    Roots                                    \n",
            "=============================================================================\n",
            "                  Real          Imaginary           Modulus         Frequency\n",
            "-----------------------------------------------------------------------------\n",
            "AR.1            1.1619           -0.4364j            1.2411           -0.0572\n",
            "AR.2            1.1619           +0.4364j            1.2411            0.0572\n",
            "-----------------------------------------------------------------------------\n",
            "[ 2.22045029  2.0448283   2.08686079  2.10787703  1.74123584  1.41850014\n",
            "  1.46240564  1.22560793  1.35545141  1.20459168 -2.95455891 -2.79620716\n",
            " -2.83636664 -1.90831903  5.8275595   5.25304203  4.77382759  4.29835916\n",
            "  1.34608637  2.64452119  3.09710037  3.95835323  3.50390104  2.59874269\n",
            "  2.68655368  2.21295825]\n",
            "    Valor Real  Previsão  Previsão AR(2)\n",
            "0          3.0       3.0        2.220450\n",
            "1          3.2       3.2        2.044828\n",
            "2         -1.7      -1.7        2.086861\n",
            "3          5.1       5.1        2.107877\n",
            "4          2.7       2.7        1.741236\n",
            "5          2.9       2.9        1.418500\n",
            "6          3.2       3.2        1.462406\n",
            "7          6.1       6.1        1.225608\n",
            "8          2.8       2.8        1.355451\n",
            "9          1.2       1.2        1.204592\n",
            "10         2.9       2.9       -2.954559\n",
            "11        -0.7      -0.7       -2.796207\n",
            "12         3.1       3.1       -2.836367\n",
            "13         2.4       2.4       -1.908319\n",
            "14        -1.9      -1.9        5.827560\n",
            "15        -3.3      -3.3        5.253042\n",
            "16         4.8       4.8        4.773828\n",
            "17         2.7       2.7        4.298359\n",
            "18         3.0       3.0        1.346086\n",
            "19        -2.2      -2.2        2.644521\n",
            "20         3.2       3.2        3.097100\n",
            "21         7.5       7.5        3.958353\n",
            "22         2.2       2.2        3.503901\n",
            "23         5.3       5.3        2.598743\n",
            "24         4.2       4.2        2.686554\n",
            "25         1.4       1.4        2.212958\n",
            "Mean MSE (Linear Regression - CV): 29.93170011520027\n",
            "Standard Deviation of MSE (Linear Regression - CV): 22.07227044251042\n",
            "Mean Squared Error (Linear Regression - Test Set): 1.034230590519274e-26\n",
            "Mean Squared Error AR(2): 12.916121594600687\n"
          ]
        }
      ],
      "source": [
        "# Descartar as observações onde a coluna 'Valor' é missing (NaN)\n",
        "df_final_cleaned = df_final.dropna(subset=['Valor'])\n",
        "\n",
        "# Verificar o resultado\n",
        "print(df_final_cleaned['vetor_medio_trimestre'])  # Exibe as primeiras linhas do DataFrame limpo\n",
        "\n",
        "# X\n",
        "X = np.array(df_final_cleaned['vetor_medio_trimestre'].tolist())\n",
        "\n",
        "# Y: Valores a serem previstos\n",
        "y = df_final_cleaned['Valor'].values\n",
        "\n",
        "# Dividir os dados em conjuntos de treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Treinando o modelo de regressão\n",
        "model = LinearRegression()\n",
        "\n",
        "# Realiza a validação cruzada com 5 dobras (folds)\n",
        "cv_scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
        "\n",
        "# Converte os scores para valores positivos\n",
        "mse_scores = -cv_scores\n",
        "\n",
        "# Calcula a média e o desvio padrão do MSE\n",
        "mean_mse = np.mean(mse_scores)\n",
        "std_mse = np.std(mse_scores)\n",
        "\n",
        "# Treinando o modelo com todos os dados\n",
        "model.fit(X, y)\n",
        "\n",
        "# Fazer previsões (opcional, se você quiser comparar com previsões em um conjunto de teste)\n",
        "#predictions = model.predict(X)\n",
        "\n",
        "# Fazer previsões no conjunto de teste\n",
        "predictions_test = model.predict(X_test)\n",
        "\n",
        "# Calcular o MSE para as previsões no conjunto de teste\n",
        "mse_linear = mean_squared_error(y_test, predictions_test)\n",
        "\n",
        "# Criar um DataFrame para comparar previsões e valores reais\n",
        "results_df = pd.DataFrame({\n",
        "    'Valor Real': y_test,\n",
        "    'Previsão': predictions_test\n",
        "})\n",
        "\n",
        "# Ajustar um modelo autoregressivo (AR) usando apenas y\n",
        "model_ar2 = AutoReg(y, lags=2)  # Use o número de lags apropriado\n",
        "model_fit_ar2 = model_ar2.fit()\n",
        "print(model_fit_ar2.summary())\n",
        "\n",
        "# Fazer previsões\n",
        "predictions_ar2 = model_fit_ar2.predict(start=len(y_train), end=len(y_train) + len(y_test) - 1)\n",
        "print(predictions_ar2)\n",
        "\n",
        "# Calcular o erro médio quadrático (MSE) para AR\n",
        "mse_ar2 = mean_squared_error(y_test, predictions_ar2)\n",
        "\n",
        "results_df['Previsão AR(2)'] = predictions_ar2  # Adiciona a nova coluna com previsões do AR(2)\n",
        "\n",
        "# Verificar os resultados\n",
        "print(results_df)\n",
        "\n",
        "# Imprimir todos os resultados para comparação\n",
        "print(f'Mean MSE (Linear Regression - CV): {mean_mse}')\n",
        "print(f'Standard Deviation of MSE (Linear Regression - CV): {std_mse}')\n",
        "print(f'Mean Squared Error (Linear Regression - Test Set): {mse_linear}')\n",
        "print(f'Mean Squared Error AR(2): {mse_ar2}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "YUrlrSVAKIAv",
        "outputId": "9dcf32b9-d6d5-48a7-de65-aa39fa0a94a4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_90afe19d-6125-454d-a160-97585c4328cc\", \"dados_extraidos.xlsx\", 2258576)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#exportando para um arquivo csv\n",
        "#print(df_final.head())\n",
        "#output_csv = 'dados_extraidos.csv'  # Nome do arquivo CSV\n",
        "#df_final.to_csv(output_csv, index=False)\n",
        "\n",
        "# Exportando para Excel\n",
        "output_excel = 'dados_extraidos.xlsx'\n",
        "df_final.to_excel(output_excel, index=False)\n",
        "\n",
        "# Download no Google Colab\n",
        "files.download(output_excel)\n",
        "\n",
        "# Se você estiver usando Google Colab, faça o download do arquivo CSV\n",
        "#try:\n",
        "    #from google.colab import files\n",
        "    #files.download(output_csv)\n",
        "#except ImportError:\n",
        "    #print(\"Não é um ambiente Colab. O arquivo está salvo como:\", output_csv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5GbV214Re_H"
      },
      "source": [
        "--------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sintonia fina de base pre treinada"
      ],
      "metadata": {
        "id": "QDA5PZlBYj-E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDCTZZHnXG7w",
        "outputId": "d02d8b73-2926-4b07-d4c7-ed2e31328f3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from gensim.models import KeyedVectors, Word2Vec\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Defina o caminho para os embeddings\n",
        "embeddings_path = '/content/drive/My Drive/Caen/TESE/word2vec-google-news-300.model.vectors.npy'\n",
        "\n",
        "# Carregar os vetores\n",
        "vectors = np.load(embeddings_path)\n",
        "\n",
        "# Tokenizar cada frase do seu DataFrame\n",
        "corpus = df['Texto Processado'].tolist()\n",
        "tokenized_corpus = [sentence.split() for sentence in corpus]  # Tokenização simples\n",
        "\n",
        "# Criar um novo modelo Word2Vec\n",
        "word2vec_model = Word2Vec(vector_size=300, window=5, min_count=1, sg=1)\n",
        "\n",
        "# Construir o vocabulário do corpus\n",
        "word2vec_model.build_vocab(tokenized_corpus)\n",
        "\n",
        "# Inicializar os vetores do novo modelo com os vetores pré-treinados\n",
        "for word in word2vec_model.wv.index_to_key:\n",
        "    if word in vectors:  # Verifique se a palavra existe nos vetores\n",
        "        word2vec_model.wv[word] = vectors[vectors.index(word)]  # Atribua o vetor pré-treinado\n",
        "\n",
        "# Treinar o modelo no seu conjunto de dados\n",
        "word2vec_model.train(tokenized_corpus, total_examples=len(tokenized_corpus), epochs=word2vec_model.epochs)\n",
        "\n",
        "# Salvar o novo modelo\n",
        "word2vec_model.save(\"/content/drive/My Drive/Caen/TESE/meu_modelo_fine_tuned_word2vec.model\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}